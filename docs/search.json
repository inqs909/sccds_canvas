[
  {
    "objectID": "posts/bootstrapping.html",
    "href": "posts/bootstrapping.html",
    "title": "The Bootstrap Method",
    "section": "",
    "text": "The Boostrap Method is an approach that can construct the sampling distribution of several estimators, not all estimators, without imposing a mathematical model on the data. The idea is that the sample \\(X_1, \\ldots, X_n\\) is generated from a distribution function called \\(F(\\theta)\\). If the sample is large enough, then the empirical distribution function \\(\\hat F_n\\) should begin to look like the true distribution function \\(F\\). This implies that the sample contains all the information of \\(F\\). Therefore, if we resample from our sample, with replacement, we are then sampling from our empirical distribution \\(\\hat F_n\\), which looks really close to the true distribution function \\(F\\).\nR Packages Used\nCode\nlibrary(tidyverse)\ntheme_set(theme_bw())\ntheme_update(axis.title = element_text(size = 24))"
  },
  {
    "objectID": "posts/bootstrapping.html#empirical-distribution-function",
    "href": "posts/bootstrapping.html#empirical-distribution-function",
    "title": "The Bootstrap Method",
    "section": "Empirical Distribution Function",
    "text": "Empirical Distribution Function\nThe empirical distribution function is designed to estimate a random variable’s distribution function. For an observed sample \\(\\{x_i\\}^n_{i=1}\\), the empirical distribution function is\n\\[\n\\hat F_n(x) = \\left\\{\\begin{array}{cc}\n0, & x &lt; x_{(1)} \\\\\n\\frac{i}{n},& x_{(i)} \\leq x &lt;x_{(i+1)},\\ i = 1,\\ldots,n-1\\\\\n1,& x_{(n)}\\leq x\n\\end{array}\n\\right.\n\\]\nwhere \\(x_{(1)}, \\ldots, x_{(n)}\\) is the ordered sample. Looking at the Glivenko-Cantelli Theorem, the empirical distribution function converges to the true function as \\(n\\rightarrow \\infty\\). For a large enough sample, \\(\\hat F_n\\) will contain the same information as \\(F\\).\n\n\n\n\n\n\nGlivenko-Cantelli Theorem\n\n\n\nIf random variables \\(X_1, X_2, \\cdots, X_n\\) are independent come from the same distribution (\\(iid\\)), then\n\\[\n\\hat F_n (x) \\rightarrow F(x)\n\\]\nconverges uniformly as \\(n\\rightarrow \\infty\\), for more information click here.\n\n\nAccordingly, the sample generated has it’s own distribution function called \\(\\hat F_n\\) where the probability of seeing any value \\(x_i\\) is \\(1/n\\). Therefore, if we were to resample \\(\\{x_i\\}^n_{i=1}\\), with replacement, it is equivalent to sampling from \\(\\hat F_n\\)."
  },
  {
    "objectID": "posts/bootstrapping.html#the-bootstrap-method",
    "href": "posts/bootstrapping.html#the-bootstrap-method",
    "title": "The Bootstrap Method",
    "section": "The Bootstrap Method",
    "text": "The Bootstrap Method\nThe Bootstrap Method is commonly used to obtain the standard error and or confidence limits of an estimator. By repeatedly sampling from \\(\\hat F_n\\), the sampling distribution of any estimator can be approximated. This is advantageous from standard mathematical models which imposes a distribution on \\(F\\), which may be completely inaccurate. The only assumption being made is that \\(\\hat F_n\\) is close the true distribution function \\(F\\).\n\nAlgorithm\nLet \\(\\boldsymbol X = (X_1, X_2, \\ldots, X_n)\\) be a random sample from a distribution \\(F\\). For an estimator \\(T(\\cdot)\\):\n\nDraw a sample \\(\\boldsymbol X^*_b\\) of size \\(n\\), with replacement, from the original data \\(\\boldsymbol X\\).\nCompute the bootstrap replicate statistic \\(T*_b = T(\\boldsymbol X^*_b)\\), where \\(T(\\cdot)\\) is the function that computes the statistic of interest.\nRepeat steps 1-2 \\(B\\) times to obtain \\(B\\) bootstrap replicates \\(T^*{T*_1, T*_2, ..., T*_B}\\).\n\nThe computed statistics from \\(B\\) samples are the empirical bootstrap distribution of the estimator, \\(T(\\boldsymbol X)\\). This can be used to compute the standard error, bias, and confidence interval of the estimator \\(T(\\boldsymbol X)\\). The number or replicates needed is open to discussion; however, research has shown \\(B=200\\) to suffiece. Larger \\(B\\) may be needed for confidence limit estimation. Another rule of thumb is having \\(B=n\\); however, this may be unfeasible for extremely large samples or computationally intensive tasks.\n\n\nStandard Error Estimation\nThe bootstrap-based standard error of an estimator is shown to provide an unbiased estimate of the true standard error. We can compute the standard eror using the following formula:\n\\[\n\\hat{se}\\left\\{T(\\boldsymbol X)\\right\\} = \\sqrt{\\frac{1}{B-1}\\sum^B_{i=1}(T^*_i-\\bar T^*)^2}\n\\] where \\(\\bar T^* = \\frac{1}{B}\\sum^B_{i=1}T^*_i\\).\n\n\nBias Estimation\nThe bootstrap-based bias estimate can be computed by the following formula:\n\\[\n\\widehat{bias}\\left\\{T(\\boldsymbol X)\\right\\} = \\bar T^* -  T(X)\n\\]\nwhere \\(\\bar T^* = \\frac{1}{B}\\sum^B_{i=1}T^*_i\\) is the mean estimate of the bootstrap samples and \\(T(X)\\) is computed statistic from the data.\n\n\nConfidence Limits Estimation\nThe confidence limits of a parameter can be estimated by using the percentiles of the bootstrap replicates. The \\((1-\\alpha) 100 \\%\\) bootstrap confidence interval can be represented as:\n\\[\n(T^*_{\\alpha/2},\\ T^*_{1-\\alpha/2})\n\\] where \\(T^*_{\\alpha/2}\\) with \\(\\alpha/2\\) quantile and \\(T^*_{1-\\alpha/2}\\) quantile of the bootstrap replicates.\n\n\nLimitation to Boostrap Methods\nLet’s say we randomly sample 5 data points from a Poisson Distribution with a rate of 51:\n\nset.seed(42)\nx &lt;- rpois(5, 1.5)\nx\n\n#&gt; [1] 3 4 1 3 2\n\n\nIf we were to use this sample and generate bootstrap estimates, we will obtain inaccurate results. This is because the empirical distribution function is a poor estimate of the true distribution function. One reason being that the \\(P(X = 0) = 0.2231\\), and our sample does not have any 0 values. Any bootstrap samples produced will never carry that information. This is why a large sample is needed so the sample space can be thoroughly explored."
  },
  {
    "objectID": "posts/bootstrapping.html#examples",
    "href": "posts/bootstrapping.html#examples",
    "title": "The Bootstrap Method",
    "section": "Examples",
    "text": "Examples\nThe examples below illustrate how to compute the bootstrap standard errors and confidence limits in a regression setting.\n\nLinear Regression\nThe mtcars data set contains information on cars from 1974 Motor Trend US Magazine. Fitting a linear regression model between the variable mpg and wt:\n\nlm(mpg ~ wt, mtcars) |&gt; summary()\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = mpg ~ wt, data = mtcars)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.5432 -2.3647 -0.1252  1.4096  6.8727 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\n#&gt; wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.046 on 30 degrees of freedom\n#&gt; Multiple R-squared:  0.7528, Adjusted R-squared:  0.7446 \n#&gt; F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\nlm(mpg ~ wt, mtcars) |&gt; confint()\n\n#&gt;                 2.5 %    97.5 %\n#&gt; (Intercept) 33.450500 41.119753\n#&gt; wt          -6.486308 -4.202635\n\n\nWe can see that the estimated model between the 2 variables is \\(\\widehat{mpg} = 37.285 - 5.345 wt\\). The standard error, based on the normal distribution, for the coefficient of wt is 0.5591. The 95% confidence interval for the coefficient of wt is (-6.486, -4.203)2.\nTo obtain the bootstrap-based standard error and 95% confidence interval, we will need to sample data points in the data set, with replacement. The user created function below will sample data points with replacement3:\n\nresample &lt;- function(df){\n  dplyr::slice_sample(df, n = nrow(df), replace = T )\n}\n\nUsing the resample, we can get a bootstrap sample:\n\nb1 &lt;- resample(mtcars)\nb1\n\n\n  \n\n\n\nNotice that some data points are repeated. We will then construct 10,000 bootstrap samples:\n\nboots &lt;- lapply(1:10000, \\(x) resample(mtcars))\n\nThe object boots is a list, with each element contain a boot replicate data set. Now we will, apply the lm function for each data set in boots.\n\nboots_lm &lt;- lapply(boots, \\(x) lm(mpg ~ wt, x))\n\nLastly, we will extract the coefficient value for each replicate4:\n\nboots_wt &lt;- lapply(boots_lm, \\(x) coef(x)[\"wt\"]) |&gt; unlist()\n\nLet’s visualize the distribution for the coefficient of wt:\n\ndata.frame(x = boots_wt) |&gt; \n  ggplot(aes(x)) +\n  geom_density()\n\n\n\n\n\n\n\n\nThe plot indicate that the coefficient for wt may not be symmetrical. The standard error can be obtained by applying the sd function to boots_wt:\n\nsd(boots_wt)\n\n#&gt; [1] 0.7046252\n\n\nThe bootstrap-based standard error is 0.71. This is different from the normal-based standard error of 0.55. The 95% confidence interval of the coefficient of wt cna be obtained by using the quantile function and setting probs = c(0.025, 0.975):\n\nquantile(boots_wt, probs = c(0.025, 0.975))\n\n#&gt;      2.5%     97.5% \n#&gt; -6.953420 -4.130759\n\n\nThe bootstrap-based 95% confidence interval is (-6.973, -4.164), which is slightly wider than the mathematical-based 95% confidence interval: (-6.486, -4.203)."
  },
  {
    "objectID": "posts/bootstrapping.html#footnotes",
    "href": "posts/bootstrapping.html#footnotes",
    "title": "The Bootstrap Method",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: The set.seed function ensures that the same random sample will be generated.↩︎\nNote: The residual analysis may suggest that the linear regression model is not appropriate.↩︎\nNote: You will need to have the dplyr function installed.↩︎\nWe will unlist the object to utilize a vector↩︎"
  },
  {
    "objectID": "posts/estimators.html",
    "href": "posts/estimators.html",
    "title": "Statistical Estimators",
    "section": "",
    "text": "Code\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/estimators.html#r-packages-used",
    "href": "posts/estimators.html#r-packages-used",
    "title": "Statistical Estimators",
    "section": "",
    "text": "Code\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/estimators.html#random-sample",
    "href": "posts/estimators.html#random-sample",
    "title": "Statistical Estimators",
    "section": "Random Sample",
    "text": "Random Sample\nWhen collecting a random sample, it is believed that the data being collected comes from a probability distribution denoted as \\(F(\\boldsymbol \\theta)\\), where \\(\\boldsymbol \\theta = (\\theta_1, \\theta_2, \\ldots, \\theta_p)^{\\mathrm T}\\) is a vector or parameters that describe the distribution. It is assumed that the random sample is a collection of random variables, denoted as \\(X_1, \\cdots, X_n\\), that are considered iid (identical and independently distributed1). Using this random sample, one infer the value of the parameters \\(\\boldsymbol \\theta\\) by functions (statistics) on the random sample."
  },
  {
    "objectID": "posts/estimators.html#statistical-estimators",
    "href": "posts/estimators.html#statistical-estimators",
    "title": "Statistical Estimators",
    "section": "Statistical Estimators",
    "text": "Statistical Estimators\nA statistical estimator is said to be a function designed to provide a point estimate, or interval estimate, of an unknown parameter in \\(\\boldsymbol \\theta\\). Common statistical estimators can be the mean, \\(\\bar X = \\frac{1}{n}\\sum^n_{i=1} X_i\\), or standard deviation, \\(S^2 = \\frac{1}{n-1}\\sum^{n}_{i=1}(X_i - \\bar X)^2\\). Other estimators can be obtained by applying a procedure such as the maximum likelihood estimation, method of moments or a Bayes Estimator."
  },
  {
    "objectID": "posts/estimators.html#sampling-distributions",
    "href": "posts/estimators.html#sampling-distributions",
    "title": "Statistical Estimators",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\nA sampling distribution can be thought as the distribution of an estimator (statistic). The reason is because the estimator is a function of random variables; therefore, the estimator itself is also a random variable. This means that the estimator will vary based on what was randomly drawn for the sample. For example, \\(\\bar X = \\frac{1}{n}\\sum^n_{i=1}X_i\\) will have a distribution depending on the distribution that generated \\(X_1, \\ldots, X_n\\).\n\nNormal Distribution Example\nAssume that \\(X_1, \\ldots, X_{25}\\overset{iid}{\\sim}N(8, 3)\\), normal distribution with mean 8 and variance 3. Depending on the sample, the value of \\(\\bar X\\) will change due to the randomness being generated. Therefore, a different sample will yield a different value of \\(\\bar X\\). The R code below will demonstrate the potential distribution \\(\\bar X\\) by simulating numerous samples from distribution above and generating the histogram of \\(\\bar X\\).\n\nSimulation\nTo simulate a random sample of 25 that follows a normal distribution, we can use the rnorm function. Afterwards, we will compute the mean of the sample.\n\nx1 &lt;- rnorm(25, 8, sqrt(3))\nmean(x1)\n\n#&gt; [1] 8.259385\n\n\nNotice that the value is close to 8. Generate (run the code below) multiple samples and see what mean are values are being produced:\n\n\n\n\n\n\n\n\nNow to visualize see the distribution of \\(\\bar X\\), we will simulate 10,000 samples, compute the mean of each sample, and construct the a histogram of the computed means.\n\n# Generate 10,000 samples of size 25 \nx_samples &lt;- replicate(10000, rnorm(25, 8, sqrt(3)))\n# Obtain the mean for all the samples\nx_means &lt;- colMeans(x_samples)\n# Plot a histogram of the sample means\ndata.frame(xbar = x_means) |&gt; \n  ggplot(aes(xbar)) +\n  geom_histogram() +\n  theme_bw()\n\n\n\n\n\n\n\n\nNotice that the values of \\(\\bar X\\) are bell shaped centered around the value 8. This makes us think that the sampling distribution for \\(\\bar X\\) may follow a normal distribution. In fact, if a random sample is said to be generated from a normal distribution, then the distribution will also be normally distributed. For this example, the distribution of \\(\\bar X\\) is \\(N(8, 3/25)\\). We can plot the probability density function on the histogram and they will closely align.\n\n# Plotting the histogram of the sample means\n# And imposing the density function of a normal distribution\n\ndata.frame(xbar = x_means, y = dnorm(x_means, 8, sqrt(3/25))) |&gt; \n  ggplot(aes(xbar, y = after_stat(density))) +\n  geom_histogram() +\n  geom_line(aes(xbar, y), col = \"red\", lwd = 1) +\n  theme_bw()"
  },
  {
    "objectID": "posts/estimators.html#central-limit-theorem",
    "href": "posts/estimators.html#central-limit-theorem",
    "title": "Statistical Estimators",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\nThe central limit theorem is the framework for several of hypothesis tests that are based on probability models.\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\nIf random variables \\(X_1, X_2, \\cdots, X_n\\) are independent come from the same distribution (\\(iid\\)), \\(E(X_i) = \\mu &lt;\\infty\\) (finite), \\(Var(X_i) = \\sigma^2&lt;\\infty\\) (finite), then\n\\[\n\\frac{\\bar X - \\mu}{\\sigma/\\sqrt n} \\overset{\\circ}{\\sim} N(0,1)\n\\]\nas \\(n\\rightarrow \\infty\\), which implies:\n\\[\n\\bar X \\overset{\\circ}{\\sim}  N(\\mu, \\sigma^2/n)\n\\]\n\n\nThe central limit theorem allows us to assume the distribution of \\(\\bar X\\) regardless of the distribution of the sample \\(X_1, X_2, \\cdots, X_n\\). The only condition is that the expected value and variance exist.\n\n\\(\\chi^2\\) Example\nAssume that \\(X_1, \\ldots, X_{n}\\overset{iid}{\\sim}\\chi^2(4)\\), Chi-Square distribution with 4 degrees of freedom. According to the central limit theorem, as \\(n\\rightarrow \\infty\\), the distribution for \\(\\bar X\\) will approximately be normal with a mean of \\(4\\) and variance \\(8/n\\).\n\nVarying Sample Sizes\nRun the following examples to show how the distribution begins to follow a normal distribution (red line) as \\(n\\) increases 15, 30, 50, 100, 1000. Change the number on line 3 to see how the distribtion changes.\n\n\n\n\n\n\n\n\n\n\n\nPoisson Example\nAssume that \\(X_1, \\ldots, X_{n}\\overset{iid}{\\sim}Pois(3.2)\\), Poisson distribution with a rate of 3.2. According to the central limit theorem, as \\(n\\rightarrow \\infty\\), the distribution for \\(\\bar X\\) will approximately be normal with a mean of \\(3.2\\) and variance \\(3.2/n\\).\n\nVarying Sample Sizes\nRun the following examples to show how the distribution begins to follow a normal distribution (red line) as \\(n\\) increases 15, 30, 50, 100, 1000. Change the number on line 3 to see how the distribtion changes."
  },
  {
    "objectID": "posts/estimators.html#footnotes",
    "href": "posts/estimators.html#footnotes",
    "title": "Statistical Estimators",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis means that the random variables \\(X_1, \\ldots, X_n\\), come from the same distribution and the value for one random variable will not influence the value of a different random variable. See here for more information.↩︎"
  },
  {
    "objectID": "posts/vc_basics.html",
    "href": "posts/vc_basics.html",
    "title": "Version Control Basics",
    "section": "",
    "text": "How many times when you are working finalizing a document and you save it as final_15.docx or something like true_final_5.docx or FINAL_FINAL_3.docx or ONLY_LOOK_AT_THIS_ONE_FINAL_2.docx. This is a common trait all of us do to ensure that we save our updates so we can look at the differences between versions. This is where version control can help organize and track your changes between different versions of a file.\nThere are 2 main tools that we can use for version control: git and GitHub. We will briefly discuss these two tools."
  },
  {
    "objectID": "posts/vc_basics.html#git",
    "href": "posts/vc_basics.html#git",
    "title": "Version Control Basics",
    "section": "Git",
    "text": "Git\nGit is the system on a computer that will track changes of all the files in a specialized directory (folder) on your computer. Git has become an essential tool for data science development of programs.\nGit is a program that is primarily used via terminal app or commandline. However, several IDE’s, such as VS Code, RStudio, and Positron have provided an easy user interface to create repositories, track and save changes, and store repositories on a remove server (GitHub).\n\nGetting Started with Git\n\n1. Initializing Repository\nWhenever you start a data science project, you first want to gather all your scripts, and possibly data if it is not sensitive and opened to be tracked, into one main project folder. This project folder will be tracked via git by making it as a repository. This can be thought as a special project going on in this folder.\n\n\n2. Develop Project\nOnce everything is set up, work on your project as normal. Update scripts, analyze data, create plots, and any other task that needs to be completed.\n\n\n3. Commit\nOnce your project, or certain files, is at a place where you want to make save and be tracked. You will stage them with the following code in a terminal app1:\ngit add fileneame\nOr you can stage all the files that have changes with\ngit add .\nThis two lines of code will tell git: “hey prepare to track and save these files”.\nAfterwards, type this in the terminal:\ngit commit -m \"WRITE MESSAGE HERE\"\nThis will save and track the files and appends a message that provides brief information of what the commit is about.\nCertain IDE’s will allow you to do all of this with out using the terminal.\n\n\n4. Save in the Cloud (GitHub)\nIf you want to save all your changes in the cloud, type this is in the terminal:\ngit push\nThis will connect to GitHub and tell it that this repository has updates that you should store.\n\n\n5. Download for the Cloud\nIf you made some changes in GitHub, or another computer that changes were pushed to GitHub. You can download those changes with the terminal commands:\ngit pull\nThis will download the changes into your computer’s repository.\n\n\n\nKey Concepts in Git\n\nRepository (Repo):\n\nA directory tracked by git containing your project files and the history of their changes.\nInitialized using git init or cloned using git clone.\n\nCommit:\n\nA snapshot of your changes, representing a specific point in your project’s history.\nCreated using git commit after staging changes.\n\nBranch:\n\nA separate line of development within a repository.\nThe default branch is typically main or master.\nNew branches are created using git branch &lt;branch-name&gt; and switched to with git checkout or git switch.\n\nRemote:\n\nA version of your repository hosted on a server, such as GitHub, GitLab, or Bitbucket.\nAllows for collaboration and centralized backups.\n\nWorking Directory, Staging Area, and Commit:\n\nWorking Directory: The files you are actively working on.\nStaging Area: A place where changes are prepared before being committed.\nCommit: A saved snapshot of the staged changes.\n\n\n\n\nEssential Commands\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ngit init\nInitialize a new Git repository.\n\n\ngit clone &lt;url&gt;\nClone a repository from a remote source.\n\n\ngit add &lt;file&gt;\nStage changes for commit.\n\n\ngit commit -m \"message\"\nSave changes to the repository.\n\n\ngit status\nCheck the status of the repository.\n\n\ngit log\nView the commit history.\n\n\ngit branch &lt;name&gt;\nCreate a new branch.\n\n\ngit switch &lt;branch&gt;\nSwitch to a different branch.\n\n\ngit pull\nFetch and merge changes from the remote.\n\n\ngit push\nPush commits to the remote repository.\n\n\n\n\n\nBest Practices\n\nWrite Meaningful Commit Messages:\n\nDescribe what changes you made and why.\n\nCommit Often:\n\nSmaller, focused commits are easier to understand and debug.\n\nCollaborate Effectively:\n\nPull changes from the remote repository frequently to avoid conflicts.\n\nReview Changes:\n\nUse git diff and git status to check your work before committing.\n\n\n\n\nUse of IDE’s\nWhile it is important to know all the terminal commands, several IDE’s will do this for you. You just need to know the concept of Stage, Commit, Push, and Pull."
  },
  {
    "objectID": "posts/vc_basics.html#github",
    "href": "posts/vc_basics.html#github",
    "title": "Version Control Basics",
    "section": "Github",
    "text": "Github\nGithub is an online platform the programmers used to store their code. Users can create repositories (a centralized back-ups) that can be updated and shared to other individuals. Imagine it as the Google Drive of programming.\n\nGetting Started with GitHub\n\n\nWhy Use GitHub?\n\nRemote Repository Hosting:\n\nGitHub hosts your Git repositories, making them accessible to collaborators around the globe.\n\nCollaboration Tools:\n\nIncludes features like pull requests, code reviews, and issue tracking.\n\nCommunity and Discovery:\n\nPublic repositories enable sharing and discovering projects, fostering an open-source community.\n\n\n\n\nKey Features of GitHub\n\nRepositories:\n\nCentralized storage for your project files and history.\nCan be public (open to everyone) or private (restricted access).\n\nPull Requests (PRs):\n\nA mechanism for proposing changes to a repository.\nFacilitates code reviews and discussions before merging changes.\n\nIssues:\n\nA built-in bug and task tracker.\nEnables collaboration on problem-solving and feature requests.\n\nActions:\n\nA CI/CD tool to automate workflows like testing and deployment.\n\nBranches and Forks:\n\nBranches: Allow isolated development within a repository.\nForks: Create a copy of a repository to experiment or contribute to the original project.\n\nGitHub Pages:\n\nHosts static websites directly from your repositories."
  },
  {
    "objectID": "posts/vc_basics.html#resources",
    "href": "posts/vc_basics.html#resources",
    "title": "Version Control Basics",
    "section": "Resources",
    "text": "Resources\nIf you want a more in depth version of using git and GitHub, take a look at the following resource table:\n\n\n\nWebsite\nDescription\n\n\n\n\nHappy Git\nProvide an overview of git and GitHub while using RStudio.\n\n\nPro Git\nA highly recommended book for those who want to gain a deep understanding of git.\n\n\nOh S***, Git!?!\nProvides troubleshooting techniques when the inevitable mistakes occur.\n\n\nGit in Simple Words\nProvides git basics in simplified words."
  },
  {
    "objectID": "posts/vc_basics.html#footnotes",
    "href": "posts/vc_basics.html#footnotes",
    "title": "Version Control Basics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMake sure to set the terminal app’s working directory to the repository↩︎"
  },
  {
    "objectID": "posts/r_stats.html",
    "href": "posts/r_stats.html",
    "title": "Data Summarization",
    "section": "",
    "text": "Modifiend from Statistical Computing"
  },
  {
    "objectID": "posts/r_stats.html#descriptive-statistics",
    "href": "posts/r_stats.html#descriptive-statistics",
    "title": "Data Summarization",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nHere, we will go over some of the basic syntax to obtain basic statistics. We will use the variables mpg and cyl from the mtcars data set. To view the data set use the head():\n\nhead(mtcars)\n\n\n  \n\n\n\nThe variable mpg would be used as a continuous variable, and the variable cyl would be used as a categorical variable.\n\nPoint Estimates\nThe first basic statistic you can compute are point estimates. These are your means, medians, etc. Here we will calculate these estimates.\n\nMean\nTo obtain the mean, use the mean(), you only need to specify x= for the data to compute the mean:\n\nmean(mtcars$mpg)\n\n#&gt; [1] 20.09062\n\n\n\n\nMedian\nTo obtain the median, use the median(), you only need to specify x= for the data to compute the median:\n\nmedian(mtcars$mpg)\n\n#&gt; [1] 19.2\n\n\n\n\nFrequency\nTo obtain a frequency table, use the table(), you only need to specify the data as the first argument to compute the frequency table:\n\ntable(mtcars$cyl)\n\n#&gt; \n#&gt;  4  6  8 \n#&gt; 11  7 14\n\n\n\n\nProportion\nTo obtain a the proportions for the frequency table, use the prop.table(). However the first argument must be the results from the table(). Use the table() inside the prop.table() to get the proportions:\n\nprop.table(table(mtcars$cyl))\n\n#&gt; \n#&gt;       4       6       8 \n#&gt; 0.34375 0.21875 0.43750\n\n\n\n\n\nVariability\nIn addition to point estimates, variability is an important statistic to report to let a user know about the spread of the data. Here we will calculate certain variability statistics.\n\nVariance\nTo obtain the variance, use the var(), you only need to specify x= for the data to compute the variance:\n\nvar(mtcars$mpg)\n\n#&gt; [1] 36.3241\n\n\n\n\nStandard deviation\nTo obtain the standard deviation, use the sd(), you only need to specify x= for the data to compute the standard deviation:\n\nsd(mtcars$mpg)\n\n#&gt; [1] 6.026948\n\n\n\n\nMax and Min\nTo obtain the max and min, use the max() and min(), respectively. You only need to specify the data as the first argument to compute the max and min:\n\nmax(mtcars$mpg)\n\n#&gt; [1] 33.9\n\nmin(mtcars$mpg)\n\n#&gt; [1] 10.4\n\n\n\n\nQ1 and Q3\nTo obtain the Q1 and Q3, use the quantile() and specify the desired quantile with probs=. You only need to specify the data as the first argument and probs= (as a decimal) to compute the Q1 and Q3:\n\nquantile(mtcars$mpg, .25)\n\n#&gt;    25% \n#&gt; 15.425\n\nquantile(mtcars$mpg, .75)\n\n#&gt;  75% \n#&gt; 22.8\n\n\n\n\n\nAssociations\nIn statistics, we may be interested on how different variables are related to each other. These associations can be represented in a numerical value.\n\nContinuous and Continuous\nWhen we measure the association between to continuous variables, we tend to use a correlation statistic. This statistic tells us how linearly associated are the variables are to each other. Essentially, as one variable increases, what happens to the other variable? Does it increase (positive association) or does it decrease (negative association). To find the correlation in R, use the cor(). You will need to specify the x= and y= which represents vectors for each variable. Find the correlation between mpg and hp from the mtcars data set.\n\ncor(mtcars$mpg, mtcars$hp)\n\n#&gt; [1] -0.7761684\n\n\n\n\nCategorical and Continuous\nWhen comparing categorical variables, it becomes a bit more nuanced in how to report associations. Most of time you will discuss key differences in certain groups. Here, we will talk about how to get the means for different groups of data. Our continuous variable is the mpg variable, and our categorical variable is the cyl variable. Both are from the mtcars data set. The tapply() allows us to split the data into different groups and then calculate different statistics. We only need to specify X= of the R object to split, INDEX= which is a list of factors or categories indicating how to split the data set, and FUN= which is the function that needs to be computed. Use the tapply() and find the mean mpg for each cyl group: 4, 5, and 6.\n\ntapply(mtcars$mpg, list(mtcars$cyl), mean)\n\n#&gt;        4        6        8 \n#&gt; 26.66364 19.74286 15.10000\n\n\n\n\nCategorical and Categorical\nReporting the association between two categorical variables is may be challenging. If you have a \\(2\\times 2\\) table, you can report a ratio of association. However, any other case may be challenging. You can report a hypothesis test to indicate an association, but it does not provide much information about the effect of each variable. You can also report row, column, or table proportions. Here we will talk about creating cross tables and report these proportions. To create a cross table, use the table() and use the first two arguments to specify the two categorical variables. Create a cross tabulation between cyl and carb from the mtcars data set.\n\ntable(mtcars$cyl, mtcars$carb)\n\n#&gt;    \n#&gt;     1 2 3 4 6 8\n#&gt;   4 5 6 0 0 0 0\n#&gt;   6 2 0 0 4 1 0\n#&gt;   8 0 4 3 6 0 1\n\n\nNotice how the first argument is represented in the rows and the second argument is in the columns. Now create table proportions using both of the variables. You first need to create the table and store it in a variable and then use the prop.table().\n\nprop.table(table(mtcars$cyl, mtcars$carb))\n\n#&gt;    \n#&gt;           1       2       3       4       6       8\n#&gt;   4 0.15625 0.18750 0.00000 0.00000 0.00000 0.00000\n#&gt;   6 0.06250 0.00000 0.00000 0.12500 0.03125 0.00000\n#&gt;   8 0.00000 0.12500 0.09375 0.18750 0.00000 0.03125\n\n\nTo get the row proportions, use the argument margin = 1 within the prop.table().\n\nprop.table(table(mtcars$cyl, mtcars$carb), \n           margin = 1)\n\n#&gt;    \n#&gt;              1          2          3          4          6          8\n#&gt;   4 0.45454545 0.54545455 0.00000000 0.00000000 0.00000000 0.00000000\n#&gt;   6 0.28571429 0.00000000 0.00000000 0.57142857 0.14285714 0.00000000\n#&gt;   8 0.00000000 0.28571429 0.21428571 0.42857143 0.00000000 0.07142857\n\n\nTo get the column proportions, use the argument margin = 2 within the prop.table().\n\nprop.table(table(mtcars$cyl, mtcars$carb), \n           margin = 2)\n\n#&gt;    \n#&gt;             1         2         3         4         6         8\n#&gt;   4 0.7142857 0.6000000 0.0000000 0.0000000 0.0000000 0.0000000\n#&gt;   6 0.2857143 0.0000000 0.0000000 0.4000000 1.0000000 0.0000000\n#&gt;   8 0.0000000 0.4000000 1.0000000 0.6000000 0.0000000 1.0000000"
  },
  {
    "objectID": "posts/r_data_manip.html",
    "href": "posts/r_data_manip.html",
    "title": "Data Cleaning in R",
    "section": "",
    "text": "Modifiend from Statistical Computing\nData manipulation consists of transforming a data set to be analyzed. Certain statistical methods require data sets to be formatted in a certain way before you can apply a certain function1. Other times, you will need to transform the data set to present to stakeholder. Therefore, being able to transform a data set is essential."
  },
  {
    "objectID": "posts/r_data_manip.html#tidyverse",
    "href": "posts/r_data_manip.html#tidyverse",
    "title": "Data Cleaning in R",
    "section": "Tidyverse",
    "text": "Tidyverse\nTidyverse is a set of packages that make data manipulation much easier. These are functions that many individuals from the R community find useful to use for data analysis. Many of the functions are descriptively named for easy remembrance. If you haven’t done so, install tidyverse:\n\ninstall.packages(\"tidyverse\")\n\nThen load tidyverse into R:\n\nlibrary(tidyverse)\n\nThis will load the main Tidyverse packages: ggplot2, tibble, tidyr, readr, purr, dplyr, stringr, and forcats."
  },
  {
    "objectID": "posts/r_data_manip.html#loading-data",
    "href": "posts/r_data_manip.html#loading-data",
    "title": "Data Cleaning in R",
    "section": "Loading Data",
    "text": "Loading Data\nThere are three methods to load a data set in R: using base R, using Tidyverse, or using RStudio. While it is important to understand how the code works to load a data set, I recommend using RStudio to import the data. It does all the work for you. Additionally, if you decide to use Tidyverse packages, RStudio will provide corresponding code for a particular file.\nTo import a data set using RStudio, head over to the environment tab (usually in the upper right hand pane) and click on the Import Dataset button. A pop-up window should look something like below.\n\n\n\n\n\n\n\n\n\nNotice how there are several options to load a data set. Depending on the format, you may want to choose one of those options. Next, notice how there are 2 “From Text”. This is because it will load text data using either Base R packages or the readr package from tidyverse. Either works, but the readr package provides the necessary code to load the data set in the window. The other one provides the code in the console.\n\nCSV Files\nA CSV file is a type of text file that where the values are separated from commas. It is very common file that you will work with. Here I will provide the code necessary to import a CSV file using either Base R or readr package code.\n\nBase R\n\nread.csv(\"FILE_NAME_AND_LOCATION\")\n\n\n\nreadr package\n\nread_csv(\"FILE_NAME_AND_LOCATION\")\n\nNotice that the functions are virtually the same.\n\n\n\nFor This Page\nYou will need to download and extract this zip file to conduct the analysis in the chapter. The code below will load the data sets you need:\n\ndata1 &lt;- read_csv(\"data/data_3_1.csv\")\ndata2 &lt;- read_csv(\"data/data_3_2.csv\")\ndata3 &lt;- read_csv(\"data/data_3_3.csv\")\ndata4 &lt;- read_csv(\"data/data_3_6.csv\")\ndata5 &lt;- read_csv(\"data/data_3_7.csv\")\ndata6 &lt;- read_csv(\"data/data_3_5.csv\")\ndata7 &lt;- read_csv(\"data/data_3_4.csv\")\n\nMake sure to change the file location as needed."
  },
  {
    "objectID": "posts/r_data_manip.html#the-pipe-operator",
    "href": "posts/r_data_manip.html#the-pipe-operator",
    "title": "Data Cleaning in R",
    "section": "The Pipe Operator |>",
    "text": "The Pipe Operator |&gt;\nThe main benefit of the pipe operator is to make the code easier to read. The base pipe |&gt; was added in R 4.0. What the pipe operator, |&gt;, does is that it will take the output from a previous function and it will use it as the input for the next function. This prevents us from nesting functions together and overwhelm us with numerous parentheses and commas. To practice, pipe data into the glimpse().\n\ndata1 |&gt; glimpse()\n\n#&gt; Rows: 1,000\n#&gt; Columns: 10\n#&gt; $ ID1  &lt;chr&gt; \"A2b6115fd\", \"Ac51c9cf1\", \"A7534d3a0\", \"A73fc5642\", \"Ae020e4bd\", …\n#&gt; $ cat1 &lt;chr&gt; \"A\", \"A\", \"A\", \"A\", \"C\", \"A\", \"A\", \"C\", \"B\", \"C\", \"B\", \"B\", \"A\", …\n#&gt; $ cat2 &lt;chr&gt; \"E\", \"D\", \"F\", \"F\", \"E\", \"D\", \"E\", \"F\", \"E\", \"E\", \"F\", \"E\", \"E\", …\n#&gt; $ var1 &lt;dbl&gt; 1.1541672, -0.3667030, -0.4203357, -2.0006336, 0.6970417, 0.46690…\n#&gt; $ var2 &lt;dbl&gt; 4, 3, 6, 5, 3, 4, 5, 0, 5, 3, 3, 8, 4, 5, 2, 5, 7, 7, 5, 1, 4, 3,…\n#&gt; $ var3 &lt;dbl&gt; 2.87981553, 0.06397162, -1.04021753, -0.31355281, 0.52613439, 2.4…\n#&gt; $ var4 &lt;dbl&gt; 3.53845785, 1.07279559, 0.22632480, 0.02128418, 2.97936180, 1.853…\n#&gt; $ var5 &lt;dbl&gt; -3.1827969, -3.1827969, -3.1827969, -3.1827969, 6.0601967, -3.182…\n#&gt; $ var6 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ var7 &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,…\n\n\nThe glimpse() provides basic variable information about data1. I recommend practice reading the code in plain English to help you understand how these functions."
  },
  {
    "objectID": "posts/r_data_manip.html#data-transformation",
    "href": "posts/r_data_manip.html#data-transformation",
    "title": "Data Cleaning in R",
    "section": "Data Transformation",
    "text": "Data Transformation\nThis section focuses on manipulating the data to obtain basic statistics, such as obtaining the mean for different categories. Many of the functions used here are from the dplyr package.\n\nSummarizing Data\nSummarizing Data is one of the most important thing in statistics. First, let’s get the mean for all the variables in data1. This is done by using the summarize_all(). All you need to do is provide the function you want R to provide. Pipe data1 into the summarize_all() and specify mean in the function.\n\ndata1 |&gt; summarise_all(mean)\n\n\n  \n\n\n\nNotice how some values are NA, this is because the variables are character data types. Therefore, it will not be able to compute the mean. Now find the standard deviation for the data set.\n\ndata1 |&gt; summarise_all(sd)\n\n\n  \n\n\n\nNow lets create a frequency table for the cat1 variable in data1. use the count() and specify the variable you are interested in:\n\ndata1 |&gt; count(cat1)\n\n\n  \n\n\n\nNow, repeat for cat2 in data1:\n\ndata1 |&gt; count(cat2)\n\n\n  \n\n\n\n\n\nGrouping\nSummarizing data is great, but sometimes you may want to group data and obtain summary statistics for those groups. This is done by using the group_by() and specify which variable you want to group. Try grouping data1 by cat1:\n\ndata1 |&gt; group_by(cat1)\n\n\n  \n\n\n\nGreat! You now have grouped data; however, this is not helpful (note everything looks the same). We can use this output and summarize the groups. All we need to do is pipe the output to the summarise_all(). Group data1 by cat1 and find the mean:\n\ndata1 |&gt; group_by(cat1) |&gt; summarise_all(mean)\n\n\n  \n\n\n\nIf we want to group by two variables, all we need to do is specify both variables in the group_by(). Group data1 by cat1 and cat2 then find the mean:\n\ndata1 |&gt; group_by(cat1,cat2) |&gt; summarise_all(mean)\n\n\n  \n\n\n\nNow, instead of finding the mean for all variables in a data set, we are only interested in viewing var1. We can use the summarise() and type the R code for finding the mean for the particular variable. Group data1 by cat1 and find the mean for var1:\n\ndata1 |&gt; group_by(cat1) |&gt; summarise(mean(var1))\n\n\n  \n\n\n\n\n\nSubsets\nOn occasion, you may need to create a subset of your data. You may only want to work with one part of your data. To create a subset of your data, use the filter() to create the subset. This will select the rows that satisfy a certain condition. Create a subset of data1 where only the positive values of var1 are present. Use the filter() and state var1&gt;0.\n\ndata1 |&gt; filter(var1&gt;0)\n\n\n  \n\n\n\nIf you know which rows you want, you can use the slice() and specify the rows as a vector. Create a subset of data1 and select the rows 100 to 200 and 300 to 400.\n\ndata1 |&gt; slice(c(100:200, 300:400))\n\n\n  \n\n\n\nIf you need random sample of your data1, use the slice_sample(n = N) and specify the number you want. It will create a data set of randomly selected rows. Create a random sample of data1 of 100 rows.\n\ndata1 |&gt;  slice_sample(n = 100)\n\n\n  \n\n\n\nIf you want a random sample that is proportion of your original data size, use the slice_sample(prop = X). Specify the proportion that you want from the data. Create a random sample of data1 that is only 2/7th of the original size.\n\ndata1 |&gt; slice_sample(prop = 2/7)\n\n\n  \n\n\n\n\n\nCreating Variables\nSome times you may need to transform variables to a new variable. This can be done by using the mutate() where you specify the name of the new variable and set equal to the transformation of other variables. Using the data2 data set, create a new variable called logvar1 and set that to the log of va1.\n\ndata2 |&gt; mutate(logvar1 = log(va1))\n\n\n  \n\n\n\nThe mutate() allows you to create multiple new variables at once. Id addition to logvar1, create a new variable called sqrtvar2 and set that equal to the square root of va2.\n\ndata2 |&gt; mutate(logvar1 = log(va1), \n                sqrtvar2 = sqrt(va2))\n\n\n  \n\n\n\nIf you want to create categorical variables, use the mutate() and the if_else(). The if_else() requires three arguments: condition argument, true argument, and false argument. The first argument requires a condition that will return a logical value. If true, then R will assign what is stated in the true argument, otherwise R will assign what is in the false argument. To begin, find the median of va1 from data2 and assign it to medval.\n\nmedval &lt;- data2$va1 |&gt; median() \n\nNo create a new variable called diva1 where if va1 is greater than the median of va1, assign it “A”, otherwise assign it “B”.\n\ndata2 |&gt; mutate(diva1=if_else(va1&gt;medval,\"A\",\"B\"))\n\n\n  \n\n\n\n\n\nMerging Datasets\nOne of the last thing is to go over how to merge data sets together. To merge the data sets, we use the full_join(). The full_join() needs two data sets (separated by commas) and the by argument which provides the variables needed (must be the same name for each data set) to merge the data sets. Merge data1 and data2 with the variable ID1.\n\nfull_join(data1, data2, by = \"ID1\")\n\n\n  \n\n\n\nThe full_join() allows you to merge data sets using two variables instead of one. All you need to do is specify by argument with a vector specifying the arguments. Merge data2 and data3 by ID_1 and ID_2.\n\nfull_join(data2, data3, by = c(\"ID_1\",\"ID_2\"))"
  },
  {
    "objectID": "posts/r_data_manip.html#reshaping-data",
    "href": "posts/r_data_manip.html#reshaping-data",
    "title": "Data Cleaning in R",
    "section": "Reshaping Data",
    "text": "Reshaping Data\nThis section focuses on reshaping the data to prepare it for analysis. For example, to conduct longitudinal data analysis, you will need to have long data. Reshaping data may be with converting data from wide to long, converting back from long to wide, splitting variables, splitting rows and merging variable. The functions used in this lesson are from the tidy package\n\nWide to Long Data\nConverting data from wide to long is necessary when the data looks like data4, view data4:\n\ndata4\n\n\n  \n\n\n\nLet’s say data4 represents biomarker data. Variable ID1 represents a unique identifier for the participant. Then X1, X2, X3, and X4 represents a value collected for a participant at different time point. This is know as repeated measurements. This data is considered wide because the repeated measurements are on the same row. To make it long, the repeated measurements must be on the same column.\nTo convert data from long to wide, we will use the pivot_longer() with the first argument taking variables of the repeated measurements, c(X1:X4) or X1:X4, second you will need to specify the names_to argument which specifies the variable name to store the long variables, lastly you will need to specify the values_to argument that specifies variable to store the values in the long data set. Convert the data4 to long and name the variable names column \"measurement\", and values column \"value\".\n\ndata4 |&gt; pivot_longer(X1:X4, \n                      names_to = \"measurement\", \n                      values_to = \"value\")\n\n\n  \n\n\n\n\n\nLong to Wide\nIf you need to convert data from long to wide, use the pivot_wider(). You will need to specify the names_from argument which specifies the variable names for the wide data set, and you will need to specify the values_from argument that specifies variable that contains the values in the long data set. Convert data5 from long to wide data. Note, you must specify the arguments for this function.\n\ndata5 |&gt; pivot_wider(names_from = measurement, \n                     values_from = value)\n\n\n  \n\n\n\n\n\nSpliting Variables\nBefore we begin, look at data6:\n\ndata6\n\n\n  \n\n\n\nNotice how the merge variable has two values separated by “/”. If we need to split the variable into two variables, we need to specify the separate(). All you need to specify is the variable you need to split, the name of the 2 new variables, in a character vector, and how to split the variable \"/\". Split the variable merge in data6 to two new variables called X1 and X2.\n\ndata6 |&gt; separate(merge, c(\"X1\", \"X2\"), \"/\")\n\n\n  \n\n\n\n\n\nSplitting Rows\nThe variable merge in data6 was split into different variables before, now instead of variables, let’s split it into different rows instead. To do this, use the separate_rows(). All you need to specify the variable name and the sep argument (must state the argument). Split the merge variable from data6 into different rows.\n\ndata6 |&gt; separate_rows(merge, sep = \"/\")\n\n\n  \n\n\n\n\n\nMerging Rows\nIf you need to merge variables together, similar to the merge variable, use the unite(). All you need to do is specify the variables to merge, the col argument which specifies the name of the new variable (as a character), and the sep argument which indicates the symbol for separate value, as a character. Note, you need to specify the bot the col argument and sep argument. Merge variable X3 and X4 in data6 to a new variable called merge2 and have the separator be a hyphen.\n\ndata6 |&gt; unite(X3, X4, col = \"merge2\", sep=\"-\")"
  },
  {
    "objectID": "posts/r_data_manip.html#applied-example",
    "href": "posts/r_data_manip.html#applied-example",
    "title": "Data Cleaning in R",
    "section": "Applied Example",
    "text": "Applied Example\nHere is an applied example where you will use what you learned from the previous lesson and convert data7 into data8. data7 has a wide data format which contains time points labeled as vX, where X represents the time point number. At each time point, the mean, sd, and median was taken. You will need to convert the data to long where each row represents a new time point, and each row will have 3 variables representing the mean, sd, and median. View both data7 and data8 to have a better idea on what is going on. Remember you need to convert data7 to data8.\n\ndata7\n\n\n  \n\n\ndata8\n\n\n  \n\n\n\nNow that you viewed the data set, type the code to convert data7 to data8. Try working it out before you look at the solution.\n\ndata7 |&gt; pivot_longer(`v1/mean`:`v4/median`,\n                      names_to = \"measurement\",\n                      values_to = \"value\") |&gt; \n          separate(measurement, c(\"time\",\"stat\"), sep=\"/\") |&gt; \n          pivot_wider(names_from = stat, values_from = value)"
  },
  {
    "objectID": "posts/r_data_manip.html#footnotes",
    "href": "posts/r_data_manip.html#footnotes",
    "title": "Data Cleaning in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLinear Mixed-Effects Models.↩︎"
  },
  {
    "objectID": "posts/randomizations.html",
    "href": "posts/randomizations.html",
    "title": "Randomization (Permutations) Tests",
    "section": "",
    "text": "Randomization tests, also known as permutation tests, are used to test whether any patterns are generated randomly or not; especially in testing differences in groups of populations. The idea is that the main null hypothesis of interest is whether the mean populations are the same, or at least one of them is different. Meaning if the recorded values needed to be assigned to a group, they will either be assigned randomly to a group or follow a specific pattern.\nA randomization test will randomly assign the recorded values to a group, which is similar to believing that the null hypothesis is true, to create a pseudo data set and ultimately a test statistic to determine a change. This pseudo data set is a permutation of how the recorded values can be arranged. If we repeat this process, different permutations of how the data can be arranged will appear. Computing the test statistic for each permuted data set will result into a distribution. This is the distribution of test statistics assuming that the recorded values are randomly assigned to a group. We can observe where our real test statistic lies to see if it is common or rare (i.e. in the tail region).\nR Packages and Functions Used\nlibrary(tidyverse) # Loading Helper Functions from Tidyverse\nlibrary(palmerpenguins)\n\ntheme_set(theme_bw()) # Setting theme for plots\ntheme_update(axis.title = element_text(size = 24))\n\n\nshuffle &lt;- function(x){ # Constructing a function to shuffle a vector\n  n &lt;- length(x)\n  return(sample(x, n))\n}\n\npenguins &lt;- penguins |&gt; drop_na() # Remove all the missing values"
  },
  {
    "objectID": "posts/randomizations.html#permutation-tests",
    "href": "posts/randomizations.html#permutation-tests",
    "title": "Randomization (Permutations) Tests",
    "section": "Permutation Tests",
    "text": "Permutation Tests\nPermutation tests conducts a statistical test by constructing the null distribution by rearranging the data points in a sample. We are testing the following hypothesis:\n\nNull hypothesis states that the rearrangements of the data points are random.\nAlternative hypothesis states that the rearrangement of the data points aren’t random."
  },
  {
    "objectID": "posts/randomizations.html#permutation-distributions",
    "href": "posts/randomizations.html#permutation-distributions",
    "title": "Randomization (Permutations) Tests",
    "section": "Permutation Distributions",
    "text": "Permutation Distributions\nLet \\(Z^{(*)}= \\{X_{i}, Y_{i}\\}\\), for \\(i = 1, \\ldots n\\) be the observed data generated from a study, where \\(X_i\\) is a numerical value and \\(Y_i = j\\), for \\(j = 1 \\ldots J\\), indicating the \\(j\\mathrm{th}\\) group the \\(i\\mathrm{th}\\) data point belongs to. Suppose \\(Z^{(k)} = \\{X_{i^*(i)}, Y_{i}\\}\\), for \\(i^* = 1, \\ldots n\\), is a permutation of the observed data point where the values of \\(X_i\\) are rearranged, while keeping \\(Y_i\\) fixed. The probability of observing \\(Z^{(k)}\\) is \\(1/n!\\). Therefore, for any statistic \\(T(Z^{(k)})\\), a sampling distribution can be constructed by using all the different permutations (\\(n!\\)). A p-value can be constructed by determining the proportion of \\(T(Z^{(k)})\\mathrm{'s}\\) that are more extreme values than \\(T(Z^{(*)})\\), the sample statistic generated from the observed data."
  },
  {
    "objectID": "posts/randomizations.html#approximate-permutation-distribution",
    "href": "posts/randomizations.html#approximate-permutation-distribution",
    "title": "Randomization (Permutations) Tests",
    "section": "Approximate Permutation Distribution",
    "text": "Approximate Permutation Distribution\nConstructing the distribution for the permutations can be challenging if the number of permutations is high! If \\(n=100\\), the number of permutations is \\(100!\\):\n\nfactorial(100)\n\n#&gt; [1] 9.332622e+157\n\n\nTherefore, simulation techniques are needed to approximate the p-value. By randomly drawing from the sample, we can approximate the p-value.\n\nAlgorithm\n\nConstruct a new data set\nFix the predictor (\\(Y\\)) variable and randomly assign a data point \\(X\\)\nCompute a test statistic using the new data set and store the value\nRepeat steps 1 and 2 for \\(N\\) times\nCompute the test statistic from the empirical sample (un-permutated)\nCount how many permutated statistics that are more extreme than the sample test statistic (\\(m\\))\nCompute the Monte Carlo p-value\n\n\\[\np = \\frac{m +1}{N + 1}\n\\]"
  },
  {
    "objectID": "posts/randomizations.html#example-penguins-data",
    "href": "posts/randomizations.html#example-penguins-data",
    "title": "Randomization (Permutations) Tests",
    "section": "Example: Penguins Data",
    "text": "Example: Penguins Data\nWe want to determine if the body mass of different penguins is affected by the species of the penguins: Adelie, Gentoo, and Species. Creating a jitter and box plot, we can see that theres is a difference between the species:\n\n\nCode\npenguins |&gt; ggplot(aes(x=species, y = body_mass_g)) +\n  geom_boxplot() +\n  geom_jitter() +\n  labs(x = \"Species\", y = \"Body Mass\")\n\n\n\n\n\n\n\n\n\nBoth Adelie and Chinstrap species have relatively the same body mass, but Gentoo have a higher body mass. The question is if the difference is due to a species effect, or simply randomness. We can conduct the following hypoteses:\n\n\n\\[\nH_0:\\ \\mu_{\\mathrm{adelie}} = \\mu_{\\mathrm{gentoo}} = \\mu_{\\mathrm{chinstrap}}\n\\]\n\n\\[\nH_a:\\ \\mathrm{At\\ least\\ one\\ pairing\\ is\\ different.}\n\\]\n\n\nWe can conduct a permutation (randomization) test determine if the null hypothesis is correct or not. By randomly shuffling body mass into different species, we can begin to see how body mass will behave if the null hypothesis is true. Below is a jitter plot displaying a permutated data points (black) against the real data points (red):\n\n\nCode\npenguins |&gt; ggplot(aes(x = species, y = body_mass_g)) +\n  labs(x = \"Species\", y = \"Body Mass\") + \n  geom_jitter(col = \"red\") +\n  geom_jitter(aes(species, shuffle(body_mass_g)))\n\n\n\n\n\n\n\n\n\nIf we repeated this process, we can generally see how multiple permutated data sets (10) behave against the real data points:\n\n\nCode\npenguins |&gt; ggplot(aes(x = species, y = body_mass_g)) +\n  labs(x = \"Species\", y = \"Body Mass\") + \n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(aes(species, shuffle(body_mass_g))) +\n  geom_jitter(col = \"red\") \n\n\n\n\n\n\n\n\n\nThe plot demonstrates that the real data is different from the permutated data. This supports the idea that species may have an effect on body mass. However, we need more permutated data sets to safely conclude this.\n\nANOVA\nInstead of making conclusions from 10 data sets, we will need to simulate much more data sets. It will be easier to use a test statistic and determine its distribution. The best statistic to use is the \\(F\\)-statistic from the Analysis of Variance (ANOVA) table since it quantifies the variation among and between the groups. We can obtain the statistic with the following R code:\n\npenguins |&gt; \n  aov(body_mass_g ~ species, data = _) |&gt; \n  anova() |&gt; \n  _$`F value`[1]\n\n#&gt; [1] 341.8949\n\n\n\n\nPermutation Test\nFirst, we will generate the \\(F\\)-statistic from the real data set.\n\nf_stat &lt;- penguins |&gt; \n  aov(body_mass_g ~ species, data = _) |&gt; \n  anova() |&gt; \n  _$`F value`[1]\n\nAfterward, create a function the will shuffle body mass, fit an ANOVA, and extract the \\(F\\)-statistic:\n\nf_sim &lt;- function(i){\n  ff &lt;- penguins |&gt; \n    aov(shuffle(body_mass_g) ~ species, data = _) |&gt; \n    anova() |&gt; \n    _$`F value`[1]\n  return(ff)\n}\n\nConstruct the distribution of \\(F\\)-statistic based on the null hypothesis with the replicate function:\n\nf_dist &lt;- replicate(1000, f_sim(1))\n\nPlot a density plot based on the null distribution, with a vertical line indicating the real \\(F\\)-statistic:\n\ntibble(x= f_dist) |&gt; \n  ggplot(aes(x, y = ..density..)) +\n  geom_histogram() +\n  geom_vline(xintercept = f_stat, col = \"red\")\n\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\nWe can see that red line is clearly far away from the null distirbution. Therefore, body mass is affeced by species of penguin. We can compute the p-value with the following code:\n\nsum(f_stat &lt; f_dist) + 1 / (length(f_dist) + 1)\n\n#&gt; [1] 0.000999001\n\n\nThe probability of observing this data set is extremely small if the null hypothesis it true."
  },
  {
    "objectID": "posts/mc.html",
    "href": "posts/mc.html",
    "title": "Monte Carlo Methods",
    "section": "",
    "text": "library(tidyverse)\nlibrary(patchwork)\n\ntheme_set(theme_bw())"
  },
  {
    "objectID": "posts/mc.html#r-setup",
    "href": "posts/mc.html#r-setup",
    "title": "Monte Carlo Methods",
    "section": "",
    "text": "library(tidyverse)\nlibrary(patchwork)\n\ntheme_set(theme_bw())"
  },
  {
    "objectID": "posts/mc.html#distributions-in-r",
    "href": "posts/mc.html#distributions-in-r",
    "title": "Monte Carlo Methods",
    "section": "Distributions in R",
    "text": "Distributions in R\nSeveral common distributions can be utilized in R with the 4 common functions:\n\n\n\n\n\n\n\nLetter\nFunctionality\n\n\n\n\nd\nreturns the height of the probability density/mass function\n\n\np\nreturns the cumulative density function value\n\n\nq\nreturns the inverse cumulative density function (percentiles)\n\n\nr\nreturns a randomly generated number"
  },
  {
    "objectID": "posts/mc.html#random-number-generator",
    "href": "posts/mc.html#random-number-generator",
    "title": "Monte Carlo Methods",
    "section": "Random Number Generator",
    "text": "Random Number Generator"
  },
  {
    "objectID": "posts/mc.html#generating-random-numbers",
    "href": "posts/mc.html#generating-random-numbers",
    "title": "Monte Carlo Methods",
    "section": "Generating Random Numbers",
    "text": "Generating Random Numbers\nA number is an outcome from a random experiment.\nRandom experiment is an experiment where the outcome is not predicted. The outcomes have a probability of being observed, whether equal or not.\n\nPsuedo Random Numbers\nThese methods are considered time-consuming when a large number values are necessary.\nWith the advent of computers, random number can be generated with the use deterministic algorithms, where a mechanism is used to make it random, such as time. Computer-generated random numbers are considered psuedo random numbers because an algorithm is used to generate them given an initial single value, known as a seed.\nSupplying a seed to a random number generator will ensure that the same numbers are produced every time.\n\n\nMersenne Twister\nThe Mersenne Twister is a widely used pseudorandom number generator (PRNG) known for its high quality and efficiency. It was developed by Makoto Matsumoto and Takuji Nishimura in 1997.\nThe default random number generator in R."
  },
  {
    "objectID": "posts/mc.html#uniform-distribution-r",
    "href": "posts/mc.html#uniform-distribution-r",
    "title": "Monte Carlo Methods",
    "section": "Uniform Distribution R",
    "text": "Uniform Distribution R\n\nDescriptionCodeWebr\n\n\nThe runif function in R will generate a value the come from a uniform distribution.\nrunif arguments:\n\nn: number of values to generate\nmin: the smallest possible value to generate\nmax: the largest possible value to generate\n\n\n\n\n\nCode\nrunif(1, 0, 1)\n\n\n#&gt; [1] 0.6525796\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistributions in R\nSeveral common distributions can be utilized in R with the 4 common functions:\n\n\n\n\n\n\n\nLetter\nFunctionality\n\n\n\n\nd\nreturns the height of the probability density/mass function\n\n\np\nreturns the cumulative density function value\n\n\nq\nreturns the inverse cumulative density function (percentiles)\n\n\nr\nreturns a randomly generated number"
  },
  {
    "objectID": "posts/mc.html#random-variable-generations",
    "href": "posts/mc.html#random-variable-generations",
    "title": "Monte Carlo Methods",
    "section": "Random Variable Generations",
    "text": "Random Variable Generations\n\nRandom Variable Generation\nSeveral distribution, common and uncommon, can be generated using a uniform random variables.\nMore complex distributions may require the use of common distributions.\n\n\nInverse-Transform Method\n\na &lt;- -20\nb &lt;- 4\nx &lt;- seq(a, b, length.out = 1000)\npnorm(x, -8, sqrt(10)) |&gt; \n  data.frame(x = x, y = _) |&gt; \n  ggplot(aes(x,y)) +\n    geom_line() +\n    ggtitle(\"CDF\") +\n    ylab(paste0(\"P(X\",\"\\u2264\",\" x)\"))\n\n\n\n\n\n\n\n\n\n\nInverse-Transformation Algorithm\n\nGenerate a random value \\(U\\) that follows a \\(U(0,1)\\)\nUsing the CDF (\\(F(X)\\)) for random variable \\(X\\), compute:\n\n\\[\nX = F^{-1}(U)\n\\]\n\n\nExponential Distribution\nAn exponential random variable is characterized by the exponential distribution, used to model waiting times or the time until an event occurs a certain number of times.\nThe exponential distribution is a gamma random variable with \\(\\alpha = 1\\).\n\n\nExponential Distribution\n\\[\nf(x) = \\frac{1}{\\lambda} \\exp\\left\\{-\\frac{x}{\\lambda}\\right\\}\n\\]\n\\[\nF(x) = 1-\\exp\\left\\{-\\frac{x}{\\lambda}\\right\\}\n\\]\n\\[\nF^{-1}(x) = -\\lambda \\log(1-x)\n\\]\n\n\nSimulating an Exponential RV\n\\[\nX \\sim Exp(2)\n\\]\n\nxe &lt;- seq(0, 4, length.out = 1000)\nu &lt;- runif(100000)\nu |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = u, y = after_stat(density))) +\n    geom_histogram() +\n    geom_line(data = data.frame(x = xe, y = dexp(xe, rate = 1/2)),\n              mapping = aes(x, y))\n\n\n\n\n\n\n\n\n\n\nSimulating an Exponential RV\n\n\nCode\nu &lt;- runif(100000)\nx &lt;- - 2 * log(1-u)\n\n\n\n\nSimulating an Exponential RV\n\nx |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = after_stat(density))) +\n    geom_histogram() +\n    geom_line(data = data.frame(x = xe, y = dexp(xe, rate = 1/2)),\n              mapping = aes(x, y)) \n\n\n\n\n\n\n\n\n\n\nExponential RV in R\n\nDescriptionCode\n\n\nThe exponential distribution can be simulated in R using the rexp function with the following arguments:\n\nn: number of values to generate\nrate: how fast would events occur\n\n\n\n\n\nCode\nrexp(1, rate = 1)\n\n\n#&gt; [1] 0.05969167\n\n\n\n\n\n\n\nDiscrete RV Inverse-Transformations\n\nGenerate a random value \\(U\\) that follows a \\(U(0,1)\\)\nUsing the CDF (\\(F(X)\\)), find the smallest integer value \\(k\\) such that:\n\n\\[\nU \\leq F(k)\n\\] 3. \\(X \\leftarrow k\\)\n\n\nPoisson Distribution\n\nxe &lt;- 0:20\nu &lt;- runif(100000)\nu |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = after_stat(density))) +\n    geom_histogram(bins = 20) +\n    geom_step(data = data.frame(x = xe, y = dpois(xe, lambda = 6)),\n              mapping = aes(x, y)) \n\n\n\n\n\n\n\n\n\n\nPoisson Distribution\n\n\nCode\nfinder &lt;- function(u){\n  x &lt;- 0\n  condition &lt;- TRUE\n  while (condition) {\n    uu &lt;- ppois(x, lambda = 6)\n    condition &lt;- uu &lt;= u\n    if(condition){\n      x &lt;- x + 1\n    }\n  }\n  return(x)\n}\nxx &lt;- sapply(u, finder)  \nxx |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = after_stat(density))) +\n    geom_histogram(bins = 21) +\n    geom_step(data = data.frame(x = xe, y = dpois(xe, lambda = 6)),\n              mapping = aes(x,y))\n\n\n\n\n\n\n\n\n\n\n\nExponential RV in R\n\nDescriptionCode\n\n\nThe Poisson distribution can be simulated in R using the rpois function with the following arguments:\n\nn: number of values to generate\nlambda: the average expected event\n\n\n\n\n\nCode\nrpois(1, lambda = 1)\n\n\n#&gt; [1] 2\n\n\n\n\n\n\n\nNormal Distribution\nObtaining the inverse distribution function of a normal distribution requires the use of numeric algorithms.\nTherefore it is computationally inefficient to use the inverse-transformation algorithm to generate normal random variables. The Box-Muller algorithm was developed to generate 2 standard normal (\\(N(0,1)\\)) random variables from uniform random variables.\n\n\nNormal Distribution\n\\[\ny = \\int^x_{-\\infty}\n\\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{z^2}{2}\\right\\}dz\n\\]\n\n\nBox-Muller Algorithm\n\nGenerate 2 independent random variables from \\(U(0,1)\\), \\(U_1\\) and \\(U_2\\)\n\\(X_1 = (-2 \\log(U_1))^{1/2}\\cos(2\\pi U_2)\\)\n\\(X_2 = (-2 \\log(U_1))^{1/2}\\sin(2\\pi U_2)\\)\n\nBoth \\(X_1\\) and \\(X_2\\) are independent \\(N(0,1)\\)\n\n\nNormal Distribution R\n\nDescriptionCode\n\n\nThe normal distribution can be simulated in R using the rnorm function with the following arguments:\n\nn: number of values to generate\nmean: the central tendency (peak)\nsd: the variation of the data (width)\n\n\n\n\n\nCode\nrnorm(1, mean = 0, sd = 1)\n\n\n#&gt; [1] 1.757749"
  },
  {
    "objectID": "posts/mc.html#accept-reject-algorithm",
    "href": "posts/mc.html#accept-reject-algorithm",
    "title": "Monte Carlo Methods",
    "section": "Accept-Reject Algorithm",
    "text": "Accept-Reject Algorithm\nThe Accept-Reject algorithm allows you to generate noncommon random variable by simulating from a common random variable.\n\nAlgorithm Set Up\nLet \\(X\\) be the random variable, that is difficult to generate, you want to generate with a pdf \\(f(x)\\).\nLet \\(Y\\) be an easily generated random variable with a pdf \\(g(y)\\). That follows the same support as \\(f(x)\\)\nLastly, multiply \\(g(y)\\) with a constant \\(c\\) such that \\(f(y)\\leq cg(y)\\).\n\n\nAlgorithm\n\nGenerate \\(Y\\) with a pdf of \\(g(y)\\)\nGenerate \\(U\\) from \\(U(0, cg(y))\\)\nAccept-Reject\nAccept: \\(U\\leq f(y)\\); \\(Y \\rightarrow X\\)\nReject: \\(U&gt;f(y)\\); repeat the algorithm\n\n\n\nModified Algorithm\n\nGenerate \\(Y\\) with a pdf of \\(g(y)\\)\nGenerate \\(U\\) from \\(U(0,1)\\)\nAccept-Reject\nAccept: \\(U\\leq f(y)/(cg(y))\\); \\(Y \\rightarrow X\\)\nReject: \\(U&gt;f(y)/(cg(y))\\); repeat the algorithm\n\n\n\nGamma Random Variable\n\nxe &lt;- seq(0, 20, length.out = 1000)\nxe |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \n    geom_line() +\n    ylab(\"Density\") \n\n\n\n\n\n\n\n\n\nGamma RV\n\nxe &lt;- seq(0, 20, length.out = 1000)\nx &lt;- rexp(100000)\nx |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = after_stat(density))) + \n    geom_histogram(aes(color = \"Exponential\")) +\n    geom_line(data = data.frame(x = xe, \n                                y = dgamma(x, shape = 2.3, scale = 1.2)), \n              aes(x,y, color = \"Gamma\")) +\n    ylab(\"Density\") +\n    theme(legend.position = \"bottom\",\n          legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nGamma RV\n\nxe &lt;- seq(0, 20, length.out = 1000)\nxe |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \n    geom_line(aes(color = \"Gamma\")) +\n    geom_line(data = data.frame(x = xe, y = dexp(xe, 1/3)), \n              aes(x,y, color = \"Exponential\")) +\n    ylab(\"Density\") +\n    theme(legend.position = \"bottom\",\n          legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nAccept-Reject Gamma RV\n\nxe &lt;- seq(0, 20, length.out = 1000)\nxe |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \n    geom_line(aes(color = \"Gamma\")) +\n    geom_line(data = data.frame(x = xe, y = 1.5 * dexp(xe, 1/3)), \n              aes(x,y, color = \"Exponential\")) +\n    ylab(\"Density\") +\n    theme(legend.position = \"bottom\",\n          legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nAccept-Reject Gamma RV\n\nxe &lt;- seq(0, 20, length.out = 1000)\nxe |&gt; \n  data.frame(x = _) |&gt; \n  ggplot(aes(x = x, y = dgamma(x, shape = 2.3, scale = 1.2))) + \n    geom_line(aes(color = \"Gamma\")) +\n    geom_line(data = data.frame(x = xe, y = 3 * dexp(xe, 1/3)), \n              aes(x,y, color = \"Exponential\")) +\n    ylab(\"Density\") +\n    theme(legend.position = \"bottom\",\n          legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nAccept-Reject Gamma RV\n\n\nCode\nx &lt;- c()\nn &lt;- 0\nwhile(n &lt; 10000){\n  e &lt;- rexp(1, 1/2.3)\n  u &lt;- runif(1)\n  f &lt;- dgamma(e, 2.3, 1/1.2)\n  g &lt;- dexp(e, 1/2.3) * 3\n  if (u &lt; (f/g)){\n    x &lt;- c(x, e)\n    n &lt;- length(x)\n  }\n}\n\n\n\n\nGamma RV\n\nx |&gt; \n  data.frame(x = _) |&gt; \n    ggplot(aes(x=x, y = after_stat(density))) + \n      geom_histogram(aes(color = \"Exponential\")) +\n      geom_line(data = data.frame(x = xe, \n                                  y = dgamma(x, shape = 2.3, scale = 1.2)), \n                aes(x,y, color = \"Gamma\")) +\n      ylab(\"Density\") +\n      theme(legend.position = \"bottom\",\n            legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nGamma Distribution R\n\nDescriptionCode\n\n\nThe gamma distribution can be simulated in R using the rgamma function with the following arguments:\n\nn: number of values to generate\nshape: describes the shape of distribution (\\(\\alpha\\))\nscale: the spread of the data (\\(\\beta\\))\n\n\n\n\n\nCode\nrgamma(1, shape = 1.2, rate = .5)\n\n\n#&gt; [1] 4.610334\n\n\n\n\n\n\n\n\nBeta RV in R\n\nDescriptionCode\n\n\nThe beta distribution can be simulated in R using the rbeta function with the following arguments:\n\nn: number of values to generate\nshape1: controls the shape of distribution\nshape2: controls the shape of distribution\n\n\n\n\n\nCode\nrbeta(1, shape1 = 1.2, shape2 = 6.5)\n\n\n#&gt; [1] 0.3989882\n\n\n\n\n\n\n\nBernoulli RV in R\n\nDescriptionCode\n\n\nThe bernoulli distribution can be simulated in R using the rbinom function with the following arguments:\n\nn: number of values to generate\nsize = 1: will give a bernoulli distribution\nprob: probability of observing 1 (success)\n\n\n\n\n\nCode\nrbinom(1, prob = .2, size = 1)\n\n\n#&gt; [1] 0\n\n\n\n\n\n\n\nBinomial RV in R\n\nDescriptionCode\n\n\nThe binomial distribution can be simulated in R using the rbinom function with the following arguments:\n\nn: number of values to generate\nsize: how many bernoulli trials to conduct\nprob: probability of observing 1 (success)\n\n\n\n\n\nCode\nrbinom(1, prob = .5, size = 25)\n\n\n#&gt; [1] 14\n\n\n\n\n\n\n\nNegative Binomial RV in R\n\nDescriptionCode\n\n\nThe negative binomial distribution can be simulated in R using the rnbinom function with the following arguments:\n\nn: number of values to generate\nsize: number of successful trials\nprob: probability of observing 1 (success)\n\n\n\n\n\nCode\nrnbinom(1, prob = .6, size = 5)\n\n\n#&gt; [1] 1"
  },
  {
    "objectID": "posts/mc.html#transformation-methods",
    "href": "posts/mc.html#transformation-methods",
    "title": "Monte Carlo Methods",
    "section": "Transformation Methods",
    "text": "Transformation Methods\n\n\\(N(0,1)\\)\n\\[\nX \\sim N(\\mu, \\sigma^2)\n\\]\n\\[\nZ = \\frac{X-\\mu}{\\sigma} \\sim N(0,1)\n\\]\n\n\n\\(N(\\mu, \\sigma^2)\\)\n\\[\nZ \\sim N(0,1)\n\\]\n\\[\nX = Z\\sigma + \\mu \\sim N(\\mu, \\sigma^2)\n\\]\n\n\n\\(\\chi^2(1)\\)\n\\[\nZ \\sim N(0,1)\n\\]\n\\[\nZ^2 \\sim \\chi^2(1)\n\\]\n\n\n\\(F(m,n)\\)\n\\[\nU \\sim \\chi^2(m)\n\\]\n\\[\nV \\sim \\chi^2(n)\n\\]\n\\[\nF = \\frac{U/m}{V/n} \\sim F(m,n)\n\\]\n\n\n\\(t(n)\\)\n\\[\nZ \\sim N(0,1)\n\\]\n\\[\nU \\sim \\chi^2(m)\n\\]\n\\[\nT = \\frac{Z}{\\sqrt{U/m}} \\sim t(n)\n\\]\n\n\n\\(Beta(\\alpha, \\beta)\\)\n\\[\nU \\sim Gamma(\\alpha,\\lambda)\n\\]\n\\[\nV \\sim Gamma(\\beta,\\lambda)\n\\]\n\\[\nX = \\frac{U}{U+V} \\sim Beta(\\alpha,\\beta)\n\\]"
  },
  {
    "objectID": "posts/mc.html#monte-carlo-integration",
    "href": "posts/mc.html#monte-carlo-integration",
    "title": "Monte Carlo Methods",
    "section": "Monte Carlo Integration",
    "text": "Monte Carlo Integration\nMonte Carlo Integration is a numerical technique to compute a numerical of an integral.\nIt relies on simulating from a know distribution to obtain the expected value of a desired function.\n\nIntegration\nIntegration is commonly used to find the area under a curve.\n\n\nExpectation\nLet \\(X\\) be a continuous random variable:\n\\[\nE(X) = \\int_{X}xf(x)dx\n\\]\n\\[\nE\\{g(X)\\} = \\int_Xg(x)f(x)dx\n\\]\n\n\nStrong Law of Large Numbers\nAs \\(n\\rightarrow \\infty\\) (ie simulate a large number of random variables):\n\\[\n\\bar X_n \\rightarrow E_f(X)\n\\]\nwhere\n\\[\n\\bar X_n \\rightarrow = \\frac{1}{n}\\sum^n_{i=1}X_i\n\\]\n\n\nStrong Law of Large Numbers\n\\[\n\\bar X_n^{(g)} \\rightarrow E_f\\{g(X)\\}\n\\]\nwhere\n\\[\n\\bar X_n^{(g)} \\rightarrow = \\frac{1}{n}\\sum^n_{i=1}g(X_i)\n\\]\n\n\nThe Expected Value of a Normal Distribution\n\\[\nE(X) = \\int^{\\infty}_{-\\infty}\\frac{x}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\} dx = \\mu\n\\]\n\n\nVariance of a Normal Distribution\n\\[\nVar(X) = E[\\{X-E(X)\\}^2] \\\\= \\int^{\\infty}_{-\\infty}\\frac{\\{x-E(X)\\}^2}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\} dx = \\sigma^2\n\\]\n\n\nUsing Monte Carlo Integration to obtain expectations\n\nSimulate from a target distribution \\(f\\)\nCalculate the mean for the expected value\n\n\n\nUsing Monte Carlo Integration\n\\[\nX \\sim N(\\mu, \\sigma^2)\n\\]\n\nx &lt;- rnorm(100000, mean = -2, sd = 3)\nmean(x)\n\n#&gt; [1] -2.002386\n\nvar(x)\n\n#&gt; [1] 9.053481\n\n\n\n\nGamma Distrbution\n\\[\nX \\sim Gamma(3,4)\n\\]\n\n\nBeta Distribution\n\\[\nX \\sim Beta(2,3)\n\\]\n\n\n\\(\\chi^2(p)\\)\n\\[\nX \\sim \\chi^2(39)\n\\]\n\n\nFinding the Probability\nIntegration is commonly used to determine the probability of observing a certain range of values for a continuous random variable.\n\\[\nP(a &lt; X &lt; b)\n\\]\n\n\nGraphical Setting\n\nx &lt;- seq(-4, 4, length.out = 1000)\ndt_two&lt;-function(x){\n            y &lt;- dnorm(x)\n            y[x&lt; -1 | x&gt;2] &lt;-NA\n            return(y)\n        }\nx |&gt; \n  (\\(.) data.frame(x = ., y = dnorm(.)))() |&gt; \n  ggplot(aes(x, y)) +\n    geom_line() +\n    stat_function(fun = dt_two, geom = \"area\", fill = \"green\")\n\n\n\n\n\n\n\n\n\n\nFinding the Propbabilities of a Random Variable\nFor a given random variable \\(X\\), finding the probability is the same as\n\\[\nE\\{I(a&lt;X&lt;b)\\} = \\int_X I(a&lt;X&lt;b) f(x) dx\n\\]\nwhere \\(I(a&lt;X&lt;b)\\) is the indicator function.\n\n\nIndicator Function\n\\[\nI(a&lt;X&lt;b) = \\left\\{\\begin{array}{cc}\n1 & a&lt;X&lt;b\\\\\n0 & \\mathrm{otherwise}\n\\end{array}\n\\right.\n\\]\n\n\nFinding the Probability\n\\[\n\\begin{align}\nE\\{I(a&lt;X&lt;b)\\} &  = \\int_X I(a&lt;X&lt;b) f(x) dx\\\\\n& = \\int_a^b f(x) dx\\\\\n& = P(a &lt; X &lt; b)\n\\end{align}\n\\]\n\n\nMonte Carlo Probability\n\nSimulate from a target distribution \\(f\\)\nCalculate the mean for \\(I(a&lt;X&lt;b)\\)\n\n\n\nNormal RV Example\nLet \\(X\\sim N(4, 2)\\), find \\(P(3 &lt; X &lt; 6)\\)\n\n\nCode\npnorm(6, 4, sqrt(2)) -  pnorm(3, 4, sqrt(2))\n\n\n#&gt; [1] 0.6816003\n\n\n\n\nUsing Monte Carlo Methods\n\n\nCode\nx &lt;- rnorm(1000000, 4, sqrt(2))\nmean((x &gt; 3 & x &lt; 6))\n\n\n#&gt; [1] 0.681141\n\n\n\n\nLogistic RV Example\nLet \\(X\\sim Logistic(3, 5)\\), find \\(P(-1 &lt; X &lt; 5)\\)\n\n\nWeibull RV Example\nLet \\(X\\sim Weibull(1, 1)\\), find \\(P(2 &lt; X &lt; 5.5)\\)\n\n\nF RV Example\nLet \\(X\\sim F(2, 45)\\), find \\(P(1 &lt; X &lt; 3)\\)\n\n\nMonte Carlo Integration\nMonte Carlo Integration can be used to evaluate finite-bounded integrals of the following form:\n\\[\n\\int^b_a g(x) dx\n\\] such that \\(-\\infty &lt;a,b&lt;\\infty\\).\n\n\nMonte Carlo Example Integration\n\\[\n\\int^1_{0} \\{\\cos(50x) - sin(20x)\\}^2dx\n\\]"
  },
  {
    "objectID": "posts/mc.html#monte-carlo-example-integration-1",
    "href": "posts/mc.html#monte-carlo-example-integration-1",
    "title": "Monte Carlo Methods",
    "section": "Monte Carlo Example Integration",
    "text": "Monte Carlo Example Integration"
  },
  {
    "objectID": "posts/mc.html#importance-sampling",
    "href": "posts/mc.html#importance-sampling",
    "title": "Monte Carlo Methods",
    "section": "Importance Sampling",
    "text": "Importance Sampling\nImportance sampling is an extension of Monte Carlo integration where it addresses the limitations of large variance of the expected value and the bounds required in integrals.\nThis is done by simulating from a random variable that has an infinite support system.\nLet’s say we are interested in finding the numerical value of the following integral:\n\\[\n\\int_{-\\infty}^\\infty g(x) dx\n\\]\nIf we view the integral as an expectation of an easily simulated random variable, we can compute the numerical value.\nLet \\(X\\) be a random variable \\(f\\), then\n\\[\n\\int_{-\\infty}^\\infty g(x) dx = \\int_{-\\infty}^\\infty \\frac{g(x)}{f(x)} f(x) dx = E\\left\\{\\frac{g(x)}{f(x)}\\right\\}\n\\]\nSince the integral is the expectation of \\(X\\), it can be obtained by taking the mean of the simulated values applied to \\(g(x)/f(x)\\).\n\nExample\n\\[\n\\int_{-\\infty}^{\\infty}  e^{-x^2/2} dx\n\\]\n\n\nExample\n\nx &lt;- rt(1000000, df = 1)\nf2 &lt;- function(x){\n  exp(-x^2/2) / dt(x, 1)\n}\nmean(f2(x))\n\n#&gt; [1] 2.505357\n\nsqrt(2*pi)\n\n#&gt; [1] 2.506628\n\n\n\n\nChoosing \\(f(x)\\)\nChoose a value \\(f(x)\\) that follows a shape close enough to \\(g(x)\\) that has the same bounds as the integral."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SCCDS Canvas Pages",
    "section": "",
    "text": "This website contains web pages housed for Canvas use.\n\n\n\n\n\n\n\n\n\nMonte Carlo Methods\n\n\n\n\n\nMar 23, 2025\n\n\n\n\n\n\n\nPositron\n\n\n\n\n\nMar 22, 2025\n\n\n\n\n\n\n\nQuarto Documents\n\n\n\n\n\nMar 21, 2025\n\n\n\n\n\n\n\nGoogle Colab and Assignments\n\n\n\n\n\nMar 21, 2025\n\n\n\n\n\n\n\nVersion Control Basics\n\n\n\n\n\nFeb 12, 2025\n\n\n\n\n\n\n\nBasic R Programming\n\n\n\n\n\nOct 26, 2024\n\n\n\n\n\n\n\nStatistical Estimators\n\n\n\n\n\nOct 11, 2024\n\n\n\n\n\n\n\nThe Bootstrap Method\n\n\n\n\n\nOct 11, 2024\n\n\n\n\n\n\n\nRandomization (Permutations) Tests\n\n\n\n\n\nOct 7, 2024\n\n\n\n\n\n\n\nAdvanced R Programming\n\n\n\n\n\nSep 28, 2024\n\n\n\n\n\n\n\nData Cleaning in R\n\n\n\n\n\nSep 28, 2024\n\n\n\n\n\n\n\nGraphics\n\n\n\n\n\nSep 28, 2024\n\n\n\n\n\n\n\nData Summarization\n\n\n\n\n\nSep 28, 2024\n\n\n\n\n\n\n\nR and RStudio\n\n\n\n\n\nSep 28, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/positron.html",
    "href": "posts/positron.html",
    "title": "Positron",
    "section": "",
    "text": "Positron is the next IDE developed by Posit, the creators of RStudio to deploy data science projects."
  },
  {
    "objectID": "posts/positron.html#installation",
    "href": "posts/positron.html#installation",
    "title": "Positron",
    "section": "Installation",
    "text": "Installation\nTo install Positron, go to their website and click on get started. Afterwards, follow the instructions to prepare your computer to use positron. This involves either installing R from CRAN or Python via pyenv (Windows). Once that is done, you can navigate to their download page, where you can download the appropriate file. Afterwards, run the installer and follow the prompts.\nAfter you install Positron, it should look like this:\n\nNote that I changed the appearance of Positron to dark theme. Here is Positron when Python is being utilized:\n\n\nVS Code\nPositron is based on Microsoft’s Code OSS platform, which makes it look very similar to visual Studio Code. It is an IDE similar to RStudio, but it is program agnostic. Additionally, it is capable to be more customizable with the use of extensions provided by Open VSX; however, you may install extensions from VS Code as well.\nTo learn more about Positron and VS Code, visit the following pages:\n\nPositron Introduction\nPositron Guides\nR Package Development\nGitHub Discussions\nVS Code Help\nVS Code Basics Videos"
  },
  {
    "objectID": "posts/positron.html#positron-application",
    "href": "posts/positron.html#positron-application",
    "title": "Positron",
    "section": "Positron Application",
    "text": "Positron Application\n\nLayout\nThe default layout has 3 main panes: an editor, console, and other (right side; session, help, viewer, …)\n\nThe editor pane allows you to create scripts and documents.\n\nThe console pane contains the language console you are working with, as well as a terminal pane.\n\nOn the top-right corner, you will notice which language is being used and the current workspace.\n\nThe button above the programming language being used can let you change the layout of Positron.\n\nClicking it will create a new window to select a desired layout.\n\nClicking the “Side-By-Side Layout” will create layout like below."
  },
  {
    "objectID": "posts/positron.html#data-science-projects",
    "href": "posts/positron.html#data-science-projects",
    "title": "Positron",
    "section": "Data Science Projects",
    "text": "Data Science Projects\nIn Positron, and VS Code, projects are created as workspaces by associating folders as specialized place called workspaces. These workspaces allow you to organize your projects as necessary, such as creating folders for you scripts, data, source files, and much more. Additionally, you can initialize a git repository for the work space\nIt is highly recommended to creat a workspace for any project you work on.\n\nPython\nTo create a Python-based workspace, you will go to the top right corner and click on the folder icon:\n\nThis will open a new drop-down menu:\n\nClick on the “New Project…” to begin creating a workspace. This will then create a new window:\n\nNow select the “Python Project” and click “Next”. Afterwards, a new window will popup asking you to create a new folder and where to store it:\n\nNotice that I have the “Initialize project at Git repository”, if you have git installed and plan to use it, it would be a good idea to initialize it. Then, a new window will popup asking you to create a new Python environment:\n\nI recommend doing so. This will create a new environment that I believe will only be used for the project. Note, you will need to install the python modules again for this new environment. A final window will popup:\n\nYou should click “New Window” for now. This will open a new session of Positron. It may take a few minutes to create the python environment, but it will work after."
  },
  {
    "objectID": "posts/positron.html#quarto",
    "href": "posts/positron.html#quarto",
    "title": "Positron",
    "section": "Quarto",
    "text": "Quarto\nWhen working in Quarto, the python chunks can send code to a console to be executed. The console is set up to use python via pyenv. However, whenever the quarto document gets an R chunk, the console will immediately change to an R console, and all the python chunks will be sent to the R console and evaluated with reticulate. This would be okay, but reticulate may not have all the python packages that pyenv has. I have tried searching for a way to have reticulate communicate with the pyenv installation, but I haven’t found anything thus far. Therefore, I recommend installing python modules via reticulate.\nYou can install a python module with:\n\nreticulate::py_install(\"polars\")"
  },
  {
    "objectID": "posts/positron.html#extensions",
    "href": "posts/positron.html#extensions",
    "title": "Positron",
    "section": "Extensions",
    "text": "Extensions"
  },
  {
    "objectID": "posts/r_adv.html",
    "href": "posts/r_adv.html",
    "title": "Advanced R Programming",
    "section": "",
    "text": "Modifiend from Statistical Computing"
  },
  {
    "objectID": "posts/r_adv.html#control-flow",
    "href": "posts/r_adv.html#control-flow",
    "title": "Advanced R Programming",
    "section": "Control Flow",
    "text": "Control Flow\nControl Flow is the process for a computer to complete a task. There are statements that a computer will read and react when executing a tasks. This section briefly discusses the main components and statements of completing tasks in R.\n\nIndexing\n\nVectors\nA vector can be a certain data type with a set number of elements. Here we construct a vector called x increasing from -5 to 5 by one unit:\n\n(x &lt;- -5:5)\n\n#&gt;  [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n\nThe vector x has 11 elements. If you want to know what the 6th element of x, you can index the 6th element from a vector. To do this, we use [] square brackets on x to index it. For example, we index the 6th element of x:\n\nx[6]\n\n#&gt; [1] 0\n\n\nWhen ever we use [] next to an R object, it will print out the data to a specific value inside the square brackets. We can index an R object with multiple values:\n\nx[1:3]\n\n#&gt; [1] -5 -4 -3\n\nx[c(3,9)]\n\n#&gt; [1] -3  3\n\n\nNotice how the second line uses the c(). This is necessary when we want to specify non-contiguous elements. Now let’s see how we can index a matrix\n\n\nMatrices\nA matrix can be indexed the same way as a vector using the [] brackets. However, since the matrix is a 2-dimensional objects, we will need to include a comma to represent the different dimensions: [,]. The first element indexes the row and the second element indexes the columns. To begin, we create the following \\(4 \\times 3\\) matrix:\n\n(x &lt;- matrix(1:12, nrow = 4, ncol = 3))\n\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    5    9\n#&gt; [2,]    2    6   10\n#&gt; [3,]    3    7   11\n#&gt; [4,]    4    8   12\n\n\nNow to index the element at row 2 and column 3, use x[2, 3]:\n\nx[2, 3]\n\n#&gt; [1] 10\n\n\nWe can also index a specific row and column:\n\nx[2,]\n\n#&gt; [1]  2  6 10\n\nx[,3]\n\n#&gt; [1]  9 10 11 12\n\n\n\n\nData Frames\nThere are several ways to index a data frame, since it is in a matrix format, you can index it the same way as a matrix. Here are a couple of examples using the mtcars data frame.\n\nmtcars[,2]\n\n#&gt;  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\nmtcars[2,]\n\n\n  \n\n\n\nHowever, a data frame has labeled components, variables, we can index the data frame with the variable names within the brackets:\n\nmtcars[, \"cyl\"]\n\n#&gt;  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nLastly, a data frame can be indexed to a specific variable using the $ operator:\n\nmtcars$cyl\n\n#&gt;  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\n\n\nLists\nLists contain elements holding different R objects. To index a specific element of a list, you will use [[]] double brackets. Below is a toy list:\n\ntoy_list &lt;- list(mtcars = mtcars,\n                 vector = rep(0, 4),\n                 identity = diag(rep(1, 3)))\n\nTo access the second element, vector element, you can type toy_list[[2]]\n\ntoy_list[[2]]\n\n#&gt; [1] 0 0 0 0\n\n\nSince the elements are labeled within the list, you can place the label in quotes inside [[]]:\n\ntoy_list[[\"vector\"]]\n\n#&gt; [1] 0 0 0 0\n\n\nThe element can be accessed using the $ notation with a list:\n\ntoy_list$vector\n\n#&gt; [1] 0 0 0 0\n\n\nLastly, you can further index the list if needed, we can access the mpg variable in mtcars from the toy_list:\n\ntoy_list$mtcars$mpg\n\n#&gt;  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n#&gt; [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n#&gt; [31] 15.0 21.4\n\ntoy_list[[\"mtcars\"]]$mpg\n\n#&gt;  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n#&gt; [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n#&gt; [31] 15.0 21.4\n\ntoy_list$mtcars[,'mpg']\n\n#&gt;  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n#&gt; [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n#&gt; [31] 15.0 21.4\n\n\n\n\n\nIf/Else Statements\nIn R, there are control flow functions that will dictate how a program will be executed. The first set of functions we will talk about are if and else statements. First, the if statement will evaluate a task, If the conditions is satisfied, yields TRUE, then it will conduct a certain task, if it fails, yields FALSE, the else statement will guide it to a different task. Below is a general format:\n\n\n\n\n\n\nImportant Concept\n\n\n\n\nif (condition) {\n  TRUE task\n} else {\n  FALSE task\n}\n\n\n\n\nExample\nBelow is an example where we generate x from a standard normal distribution and print the statement ‘positive’ or ‘non-positive’ based on the condition x &gt; 0.\n\nx &lt;- rnorm(1)\n\n## if statements\nif (x &gt; 0){\n  print(\"Positive\")\n} else {\n  print(\"Non-Positive\")\n}\n\n#&gt; [1] \"Positive\"\n\n\nWhat if we want to print the statement ‘negative’ as well if the value is negative? We will then need to add another if statement after the else statement since x &gt; 0 only lets us know if the value is positive.\n\nx &lt;- rnorm(1)\n\nif (x &gt; 0){\n  print(\"Positive\")\n} else if (x &lt; 0) {\n  print(\"Negative\")\n}\n\n#&gt; [1] \"Negative\"\n\n\nAbove, we add the if statement with condition (x &lt; 0) indicating if the number is negative. Lastly, if x is ever \\(0\\), we will want R to let us know it is \\(0\\). We can achieve this by adding one last else statement:\n\nx &lt;- rnorm(1)\n\nif (x &gt; 0){\n  print(\"Positive\")\n} else if (x &lt; 0) {\n  print(\"Negative\")\n} else {\n  print(\"Zero\")\n}\n\n#&gt; [1] \"Negative\"\n\n\n\n\n\nfor loops\nA for loop is a way to repeat a task a certain amount of times. Every time a loop repeats a task, we state it is an iteration of the loop. For each iteration, we may change the inputs by a certain way, either from an indexed vector, and repeat the task. The general anatomy of a loop looks like:\n\n\n\n\n\n\nImportant Concept\n\n\n\n\nfor (i in vector){\n  perform task\n}\n\n\n\nThe for statement indicates that you will repeat a task inside the brackets. The i in the parenthesis controls how the task will be completed. The in statement tells R where i can look for the values, and vectorr is a vector R object that contains the values i can be. It also controls how many times the task will be repeated based on the length of the vector.\nLearning about a loop is quite challenging, my recommendation is to read the section below and break the example code so you can understand how a for loop works.\n\nBasic for loop\nLet’s say we want R to print one to five separately. We can achieve this by repeating the print() 5 times.\n\nprint(1); print(2); print(3); print(4); print(5)\n\n#&gt; [1] 1\n\n\n#&gt; [1] 2\n\n\n#&gt; [1] 3\n\n\n#&gt; [1] 4\n\n\n#&gt; [1] 5\n\n\nHowever, this takes quite awhile to type up. Let’s try to achieve the same task using a for loop.\n\nfor (i in 1:5){\n  print(i)\n}\n\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\n\nHere, i will take a value from the vector 1:5,1 Then, R will print out what the value of i is.\nNow, let’s try another example with letters. To begin, create a new vector called letters_10 containing the first 10 letters of the alphabet. Use the vector letters to construct the neww vector.\n\nletters_10 &lt;- letters[1:10]\n\nNow, we will use a loop to print out the first 10 letters:\n\nfor (i in 1:10) {\n  print(letters_10[i])\n}\n\n#&gt; [1] \"a\"\n#&gt; [1] \"b\"\n#&gt; [1] \"c\"\n#&gt; [1] \"d\"\n#&gt; [1] \"e\"\n#&gt; [1] \"f\"\n#&gt; [1] \"g\"\n#&gt; [1] \"h\"\n#&gt; [1] \"i\"\n#&gt; [1] \"j\"\n\n\nHere, we have i take on the values 1 through 10. Using those values, we will index the vector letters_10 by i. The resulting letter will then be printed. This task repeated 10 times.\nLastly, we can replace 1:10 by letters_10 instead:\n\nfor (i in letters_10){\n  print(i)\n}\n\n#&gt; [1] \"a\"\n#&gt; [1] \"b\"\n#&gt; [1] \"c\"\n#&gt; [1] \"d\"\n#&gt; [1] \"e\"\n#&gt; [1] \"f\"\n#&gt; [1] \"g\"\n#&gt; [1] \"h\"\n#&gt; [1] \"i\"\n#&gt; [1] \"j\"\n\n\nThis is because letters_10 are the values that we want to print and i takes on the value of letters_10 each time.\n\n\nNested for loops\nA nested for loop is a loop that contain a loop within. Below is an example of 3 for loops nested within each other. Below is a general example:\n\n\n\n\n\n\nImportant Concept\n\n\n\n\nfor (i in vector_1) {\n  for (ii in vector_2) {\n    for (iii in vector_3) {\n      perform task\n    }\n  }\n}\n\n\n\nAs an example, we will use the greekLetter::2 and use the greek_vector vector to obtain greek letters in R. Lastly, create a vector called greek_10.\n\nlibrary(greekLetters)\ngreek_10 &lt;- print_greeks()[1:10]\n\n#&gt;                  alpha                   beta                  gamma \n#&gt;                    \"α\"                    \"β\"                    \"γ\" \n#&gt;                  delta                epsilon                   zeta \n#&gt;                    \"δ\"                    \"ε\"                    \"ζ\" \n#&gt;                    eta                  theta                   iota \n#&gt;                    \"η\"                    \"θ\"                    \"ι\" \n#&gt;                  kappa                 lambda                     mu \n#&gt;                    \"κ\"                    \"λ\"                    \"μ\" \n#&gt;                     nu                     xi                omicron \n#&gt;                    \"ν\"                    \"ξ\"                    \"ο\" \n#&gt;                     pi                    rho                  sigma \n#&gt;                    \"π\"                    \"ρ\"                    \"σ\" \n#&gt;                    tau                upsilon                    phi \n#&gt;                    \"τ\"                    \"υ\"                    \"φ\" \n#&gt;                    chi                    psi                  omega \n#&gt;                    \"χ\"                    \"ψ\"                    \"ω\" \n#&gt;                  Alpha                   Beta                  Gamma \n#&gt;                    \"Α\"                    \"Β\"                    \"Γ\" \n#&gt;                  Delta                Epsilon                   Zeta \n#&gt;                    \"Δ\"                    \"Ε\"                    \"Ζ\" \n#&gt;                    Eta                  Theta                   Iota \n#&gt;                    \"Η\"                    \"Θ\"                    \"Ι\" \n#&gt;                  Kappa                 Lambda                     Mu \n#&gt;                    \"Κ\"                    \"Λ\"                    \"Μ\" \n#&gt;                     Nu                     Xi                Omicron \n#&gt;                    \"Ν\"                    \"Ξ\"                    \"Ο\" \n#&gt;                     Pi                    Rho                  Sigma \n#&gt;                    \"Π\"                    \"Ρ\"                    \"Σ\" \n#&gt;                    Tau                Upsilon                    Phi \n#&gt;                    \"Τ\"                    \"Υ\"                    \"Φ\" \n#&gt;                    Chi                    Psi                  Omega \n#&gt;                    \"Χ\"                    \"Ψ\"                    \"Ω\" \n#&gt;               infinity         leftrightarrow                 forall \n#&gt;                    \"∞\"                    \"⇔\"                    \"∀\" \n#&gt;                  exist               notexist               emptyset \n#&gt;                    \"∃\"                    \"∄\"                    \"∅\" \n#&gt;              elementof           notelementof           proportional \n#&gt;                    \"∈\"                    \"∉\"                    \"∝\" \n#&gt;    asymptoticallyEqual notasymptoticallyEqual            approxEqual \n#&gt;                    \"≃\"                    \"≄\"                    \"≅\" \n#&gt;            almostEqual                    leq                    geq \n#&gt;                    \"≈\"                    \"≤\"                    \"≥\" \n#&gt;               muchless            muchgreater              leftarrow \n#&gt;                    \"≪\"                    \"≫\"                    \"⇐\" \n#&gt;             rightarrow                  equal               notEqual \n#&gt;                    \"⇒\"                   \"＝\"                    \"≠\" \n#&gt;               integral         doubleintegral         tripleintegral \n#&gt;                    \"∫\"                    \"∬\"                    \"∭\" \n#&gt;             logicalAnd              logicalOr           intersection \n#&gt;                    \"∧\"                    \"∨\"                    \"∩\" \n#&gt;                  union \n#&gt;                    \"∪\"\n\n\nFor this example, we want R to print “a” and “\\(\\alpha\\)” together as demonstrated below3:\n\nprint(paste0(letters_10[1], greek_10[1]))\n\n#&gt; [1] \"aα\"\n\n\nNow let’s repeat this process to print all possible combinations of the first 3 letters and 3 greek letters:\n\nfor (i in 1:3){\n  for (ii in 1:3){\n    print(paste0(letters_10[i], greek_10[ii]))\n  }\n}\n\n#&gt; [1] \"aα\"\n#&gt; [1] \"aβ\"\n#&gt; [1] \"aγ\"\n#&gt; [1] \"bα\"\n#&gt; [1] \"bβ\"\n#&gt; [1] \"bγ\"\n#&gt; [1] \"cα\"\n#&gt; [1] \"cβ\"\n#&gt; [1] \"cγ\"\n\n\n\n\n\nbreak\nA break statement is used to stop a loop midway if a certain condition is met. A general setup of break statement goes as follows:\n\n\n\n\n\n\nImportant Concept\n\n\n\n\nfor (i in vector){\n  if (condition) {break}\n  else {\n    task\n  }\n}\n\n\n\nAs you can see there is an if statement in the loop. This is used to tell R when to break the loop. If the if statement was not there, then the loop will break without iterating.\nTo demonstrate the break statement, we will simulate from a \\(N(1,1)\\) until we have 30 positive numbers or we simulate a negative number.\n\nx &lt;- rep(NA,length = 30)\n\nfor (i in seq_along(x)){\n  y &lt;- rnorm(1,1)\n  if (y&lt;0) {\n    break\n  }\n  else {\n    x[i] &lt;- y\n  }\n}\nprint(x)\n\n#&gt;  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n#&gt; [26] NA NA NA NA NA\n\nprint(y)\n\n#&gt; [1] -0.609801\n\n\nNotice that the vector does not get filled up all the way, that is because the loop will break once a negative number is simulated\n\n\nnext\nSimilar to the break statement, the next statement is used in loops that will tell R to move on to the next iteration if a certain condition is met.\n\n\n\n\n\n\nImportant Note\n\n\n\n\nfor (i in vector){\n  if (condition) {\n    next\n  } else {\n    task\n  }\n}\n\n\n\nThe main difference here is that a next statement is used instead of a break statement.\nGoing back to simulating positive numbers, we will use the same setup but change it to a next statement.\n\nx &lt;- rep(NA,length = 30)\n\nfor (i in seq_along(x)){\n  y &lt;- rnorm(1,1)\n  if (y&lt;0) {\n    next\n  }\n  else {\n    x[i] &lt;- y\n  }\n}\nprint(x)\n\n#&gt;  [1] 1.01181735 1.62286792 0.30183584 0.48362528 1.78402554 1.13085513\n#&gt;  [7] 1.57508218 0.65478643 3.17777029 0.56007300 1.19407508 0.90257557\n#&gt; [13] 0.59252054 1.10781445 2.47523055 0.18030672 0.05659195 0.83101216\n#&gt; [19] 0.69962236 1.89899451 1.66595079 1.35667846 1.42644458 2.09965482\n#&gt; [25] 3.11142281 0.70522148 0.12086895 0.13122092 1.60640385 1.27149114\n\n\nAs you can see, the vector contains missing values, these were the iterations that a negative number was simulated.\n\n\nwhile loop\nThe last loop that we will discuss is a while loop. The while loop is used to keep a loop running until a certain condition is met. To construct a while loop, we will use the while statement with a condition attached to it. In general, a while loop will have the following format:\n\n\n\n\n\n\nImportant Concept\n\n\n\n\nwhile (condition) {\n  task\n  update condition\n}\n\n\n\nAbove, we see that the while statement is used followed by a condition. Then the loop will complete its task and update the condition. If the condition yields a FALSE value, then the loop will stop. Otherwise, it will continue.\n\nBasic while loops\nTo implement a basic while loop, we will work on the previous example of simulating positive numbers. We want to simulate 30 positive numbers from \\(N(0,1)\\) until we have 30 values. Here, our condition is that we need to have 30 numbers. Therefore we can use the following code to simulate the values:\n\nx &lt;- c()\nsize &lt;- 0\nwhile (size &lt; 30){\n  y &lt;- rnorm(1) \n  if (y &gt; 0) {\n    x &lt;- c(x, y)\n  }\n  size &lt;- length(x)\n}\nprint(size)\n\n#&gt; [1] 30\n\nprint(x)\n\n#&gt;  [1] 0.5603081 0.1877319 0.4000447 0.9373778 2.1430376 1.0727699 1.0795590\n#&gt;  [8] 0.7911710 0.4571208 0.3365296 0.4659813 0.7590729 0.2147407 1.2902632\n#&gt; [15] 0.1750396 1.0243279 0.5179792 1.4395258 0.1833139 0.4362575 0.4903001\n#&gt; [22] 0.2625778 0.2064332 1.2284271 1.4033754 1.2431922 1.2705217 0.1728668\n#&gt; [29] 1.6632352 0.2399995\n\n\nNotice that we do not use an else statement. This is because we do not need R to complete a task if the condition fails.\n\n\nInfinite while loops\nWith while loops, we must be weary about potential infinite loops. This occurs when the condition will never yield a FALSE value. Therfore, R will never stop the loop because it does not know when to do this.\nFor example, let’s say we are interest if \\(y=sin(x)\\) will converge to a certain value. As you know it will not converge to a certain value; however, we can construct a while loop:\n\nx &lt;- 1\ndiff &lt;- 1\nwhile (diff &gt; 1e-20) {\n  old_x &lt;- x\n  x &lt;- x + 1\n  diff &lt;- abs(sin(x) - sin(old_x))\n}\nprint(x)\nprint(diff)\n\nMy condition above is to see if the absolute difference between sequential values is smaller than \\(10^{-20}\\). As you may know, the absolute difference will never become that small. Therefore, the loop will continue on without stopping.\nTo prevent an infinite while loop, we can add a counter to the condition statement. This counter will also need to be true for the loop to continue. Therefore, we can arbitrarily stop it when the loop has iterated a certain amount of times. We just need to make sure to add one to the counter every time it iterates it. Below is the code that adds a counter to the while loop:\n\nx &lt;- 1\ncounter &lt;- 0\ndiff &lt;- 1\nwhile (diff &gt; 1e-20 & counter &lt; 10^3) {\n  old_x &lt;- x\n  x &lt;- x + 1\n  diff &lt;- abs(sin(x) - sin(old_x))\n  counter &lt;- counter + 1\n}\nprint(x)\n\n#&gt; [1] 1001\n\nprint(diff)\n\n#&gt; [1] 0.09311106\n\nprint(counter)\n\n#&gt; [1] 1000"
  },
  {
    "objectID": "posts/r_adv.html#functions",
    "href": "posts/r_adv.html#functions",
    "title": "Advanced R Programming",
    "section": "Functions",
    "text": "Functions\nThe functionality in R is what makes it completely powerful compared to other statistical software. There are several pre-built functions, and you can extend R’s functionality further with the use of R Packages.\n\nBuilt-in Functions\nThere are several available functions in R to conduct specific statistical methods. The table below provides a set of commonly used functions:\n\n\n\nFunctions\nDescription\n\n\n\n\naov()\nFits an ANOVA Model\n\n\nlm()\nFits a linear model\n\n\nglm()\nFits a general linear model\n\n\nt.test()\nConducts a t-test\n\n\n\nSeveral of these functions have help documentation that provide the following sections:\n\n\n\n\n\n\n\nSection\nDescription\n\n\n\n\nDescription\nProvides a brief introduction of the function\n\n\nUsage\nProvides potential usage of the function\n\n\nArguments\nArguments that the function can take\n\n\nDetails\nAn in depth description of the function\n\n\nValue\nProvides information of the output produced by the function\n\n\nNotes\nAny need to know information about the function\n\n\nAuthors\nDevelopers of the function\n\n\nReferences\nReferences to the model and function\n\n\nSee Also\nProvide information of supporting functions\n\n\nExamples\nExamples of the function\n\n\n\nTo obtain the help documentation of each function, use the ? operator and function name in the console pane.\n\n\nGeneric Functions\nCommonly used functions, such as summary() and plot() functions, are considered generic functions where their functionality is determined by the class of an R object. For example, the summary() function is a generic function for several types of functions: summary.aov(), summary.lm(), summary.glm(), and many more. Therefore, the appropriate function is needed depending the type of R object. This is where generic functions come in. We can use a generic function, ie summary(), to read the type of object and then apply to correct procedure to the object.\n\n\nUser-built Functions\nWhile R has many capable functions that can be used to analyze your data, you may need to create a custom function for specific needs. For example, if you find yourself writing the same to repeat a task, you can wrap the code into a user-built function and use it for analysis.\nTo create a user-built function, you will using the function() to create an R object that is a function. To use the function Inside the funtion() parentheses, write the arguments that need to specified for your function. These are arguments you choose for the function.\n\nAnatomy\nIn general function we construct a function with the following anatomy:\n\nname_of_function &lt;- function(data_1, data_2 = NULL, \n                             argument_1, argument_2 = TRUE, argument_3 = NULL,\n                             ...){\n  # Conduct Task\n  # Conduct Task\n  output_object &lt;- Tasks\n  return(output_object)\n}\n\nHere, we are creating an R function called name_of_function that will take the following arguments: data_1, data_2, argument_1, argument_2, argument_3, and .... From this function, it requires us to supply data for data_1 and argument_1. Arguments data_2 and argument_3 are not required, but can be utilized in the function if necessary. Argument argument_2 is also required for the function, but it it has a default setting (in this case TRUE) if it is not specified. Lastly, the ... argument allows you to pass other arguments to R built in functions if they are present. For example, we may use the plot() to create graphics and want to manipulate the output plot further, but do not want to specify the arguments in the user-based function. In the function itself, we will complete the necessary tasks and then use the return() to return the output.\n\n\nExample\nTo begin, let’s create a function that squares any value:\n\nx_square &lt;- function(x){x^2}\n\nAbove, a new function called x_square is being created and it will take values of x and square it. Here are a couple of examples of x_square():\n\nx_square(4)\n\n#&gt; [1] 16\n\nx_square(5)\n\n#&gt; [1] 25\n\n\nThe mtcars data set has several numeric variables that can be used for analysis. Let’s say we want to apply a function (x_square()) to the sum of a specific variable and return the value. Then let’s further complicate the function by allowing the sum of 2 variables, take the log of the sum and dividing the value if necessary. Below is the code for such function called summing:\n\nsumming &lt;- function(vec1, vec2 = NULL, FUN, log_val = FALSE, divisor_val = NULL){\n  FUN &lt;- match.fun(FUN)\n  wk_vec &lt;- c(vec1, vec2)\n  fun_sum_val &lt;- FUN(sum(wk_vec))\n  lval &lt;- NULL\n  if (isTRUE(log_val)){\n    lval &lt;- log(fun_sum_val)\n  } else {\n    lval &lt;- fun_sum_val\n  }\n  if (!is.null(divisor_val)){\n    dval &lt;- divisor_val\n  } else {dval &lt;- 1}\n  output &lt;- lval/dval\n  return(output)\n}\n\nNow let’s try obtaining the\n\nsum(mtcars$mpg)^2\n\n#&gt; [1] 413320.4\n\nsumming(mtcars$mpg, FUN = x_square)\n\n#&gt; [1] 413320.4\n\nlog(sum(c(mtcars$mpg,mtcars$disp))^2)\n\n#&gt; [1] 17.98088\n\nsumming(mtcars$mpg, mtcars$disp, x_square, T)\n\n#&gt; [1] 17.98088\n\nlog(sum(c(mtcars$mpg,mtcars$disp))^2)/5\n\n#&gt; [1] 3.596177\n\nsumming(mtcars$mpg, mtcars$disp, x_square, T, 5)\n\n#&gt; [1] 3.596177"
  },
  {
    "objectID": "posts/r_adv.html#apply-functions",
    "href": "posts/r_adv.html#apply-functions",
    "title": "Advanced R Programming",
    "section": "*apply Functions",
    "text": "*apply Functions\n*apply functions are used to iterate a function through a set of elements in a vector, matrix, or list. The process will return a vector or list depending on what is requested.\n\napply()\nThe apply() function is used to apply a function to the margins of an array or matrix. It will iterate between the elements, apply a function to the data, and return a vector, array or list if necessary. To use the apply() function, you will need to specify three arguments, X or the array, MARGIN which margin to apply the function on, and FUN the function.\nBelow we calculate the row means and column means using the apply function for a \\(5 \\times 4\\) matrix containing the elements 1 through 20:\n\nx &lt;- matrix(1:20, nrow = 5, ncol = 4)\n\n# Row Means\napply(x, 1, mean)\n\n#&gt; [1]  8.5  9.5 10.5 11.5 12.5\n\n# Col Means\napply(x, 2, mean)\n\n#&gt; [1]  3  8 13 18\n\n\n\n\nlapply()\nThe lapply() function is used to apply a function to all elements in a vector or list. The lapply() function will then return a list as the output.\n\n\nsapply()\nThe sapply() function is used to apply a function to all elements in a vector or list. Afterwards, the sapply() will return a “simplified” version of the list format. This could be a vector, matrix, or array."
  },
  {
    "objectID": "posts/r_adv.html#anonymous-functions",
    "href": "posts/r_adv.html#anonymous-functions",
    "title": "Advanced R Programming",
    "section": "Anonymous Functions",
    "text": "Anonymous Functions\nAnonymous functions are functions that R temporarily creates to conduct a task. They are commonly used with the *apply functions, piping or within functions. To create an anonymous function, we use the function() function to create a function.\nFor example, let x be a vector with the values 1 through 15. Let’s say we want to apply the function \\(f(x) = x^2+\\ln(x) + e^x/x!\\). We can evaluate the function as the expression in the function:\n\nx &lt;- 1:15\nx^2 + log(x) + exp(x)/factorial(x)\n\n#&gt;  [1]   3.718282   8.387675  13.446202  19.661217  27.846214  38.352077\n#&gt;  [7]  51.163496  66.153374  83.219555 102.308655 123.399395 146.485246\n#&gt; [13] 171.565020 198.639071 227.708053\n\n\nLet’s say we could not do that, we need to evaluate the function for each value of x. We can use the sapply() function with an anonymous function:\n\nsapply(x, function(x) x^2 + log(x) + exp(x) / factorial(x))\n\n#&gt;  [1]   3.718282   8.387675  13.446202  19.661217  27.846214  38.352077\n#&gt;  [7]  51.163496  66.153374  83.219555 102.308655 123.399395 146.485246\n#&gt; [13] 171.565020 198.639071 227.708053\n\n\nIn R 4.1.0, developers introduce a shortcut approach to create functions. You can create a function using \\() expression, and specify the arguments for your function within the parenthesis. Reworking the previous code, we can use \\() instead of function():\n\nsapply(x, \\(x) x^2 + log(x) + exp(x)/factorial(x))\n\n#&gt;  [1]   3.718282   8.387675  13.446202  19.661217  27.846214  38.352077\n#&gt;  [7]  51.163496  66.153374  83.219555 102.308655 123.399395 146.485246\n#&gt; [13] 171.565020 198.639071 227.708053\n\nsapply(x, \\(.) .^2 + log(.) + exp(.)/factorial(.))\n\n#&gt;  [1]   3.718282   8.387675  13.446202  19.661217  27.846214  38.352077\n#&gt;  [7]  51.163496  66.153374  83.219555 102.308655 123.399395 146.485246\n#&gt; [13] 171.565020 198.639071 227.708053\n\n\nNotice that the argument in the anonymous function can be anything."
  },
  {
    "objectID": "posts/r_adv.html#scripting-and-piping-in-r",
    "href": "posts/r_adv.html#scripting-and-piping-in-r",
    "title": "Advanced R Programming",
    "section": "Scripting and Piping in R",
    "text": "Scripting and Piping in R\nThis section provides the basic components to script an R file.\n\nCommenting\nA comment is used to describe your code within an R Script. To comment your code in R, you will use the # key, and R will not execute any code after the symbol. The # key can be used to anywhere in the line, from beginning to midway. It will not execute any code coming after the #.\nAdditionally, commenting is a great way to debug long scripts of code or functions. You comment certain lines to see if any errors are being produced. It can be used to test code line by line with out having to delete everything.\n\n\nScripting\nWhen writing a script, it is important to follow a basic structure for you to follow your code. While this structure can be anything, the following sections below has my main recommendations for writing a script. The most important part is the Beginning of the Script section.\n\nBeginning of the Script\nLoad any R packages, functions/scripts, and data that you will need for the analysis. It is also recommended to record the date the script is being executed.\n\n## Todays data \nanalysis_data &lt;- format(Sys.time(),\"%Y-%m-%d-%H-%M\")\n\n## R Packages\nlibrary(tidyverse)\nlibrary(magrittr)\n\n## Functions\nsource(\"fxs.R\")\nRcpp::sourceCpp(\"fxs.cpp\")\n\n## Data\ndf1 &lt;- read_csv(\"file.csv\")\ndf2 &lt;- load(\"file.RData\") %&gt;% get\n\n\n\nMiddle of the Script\nRun the analysis, including pre and post analysis.\n\n## Pre Analysis\ndf1_prep &lt;- Prep_data(df1)\ndf2_prep &lt;- Prep_data(df2)\n\n## Analysis\ndf1_analysis &lt;- analyze(df1_prep)\ndf2_analysis &lt;- analyze(df2_prep)\n\n## Post Analysis\ndf1_post &lt;- Prep_post(df1_anlysis)\ndf2_post &lt;- Prep_post(df2_anlysis)\n\n\n\nEnd of the Script\nSave your results in an R Data file:\n\n## Save Results\nres &lt;- list(df1 = list(pre = df1_prep,\n                       analysis = df1_analysis,\n                       post = df1_post),\n            df2 = list(pre = df2_prep,\n                       analysis = df2_analysis,\n                       post = df2_post))\nfile_name &lt;- paste0(\"results_\", analysis_data, \".RData\")\nsave(res, file = file_name)\n\n\n\n\nPipes\nIn R, pipes are used to transfer the output from one function to the input of another function. Piping will then allow you to chain functions to run an analysis. Since R 4.1.0, there are two version of pipes, the base R pipe and the pipes from the magrittr package. The table below provides a brief description of each type pipes\n\n\n\n\n\n\n\n\n\nPipe\nName\nPackage\nDescription\n\n\n\n\n|&gt;\nR Pipe\nBase\nThis pipe will use the output of the previous function as the input for the first argument following function.\n\n\n%&gt;%\nForward Pipe\nmagrittr\nThe forward pipe will use the output of the previous function as the input of the following function.\n\n\n%$5\nExposition Pipe\nmagrittr\nThe exposition function will expose the named elements of an R object (or output) to the following function.\n\n\n%T&gt;%\nTee Pipe\nmagrittr\nThe Tee pipe will evaluate the next function using the output of the previous function, but it will not retain the output of the next function and utilize the output of the previous function.\n\n\n%&lt;&gt;%\nAssignment Pipe\nmagrittr\nThe assignment pipe will rewrite the object that is being piped into the next function.\n\n\n\nEhen using the pipe, it is recommend to only string a limited amount of functions (~10) to maintain code readability and conciseness. Any more functions may make the code incoherent.\nIf you plan to use magrittr’s pipe, it is recommend to load the magrittr package instead of tidyverse package.\n\nlibrary(magrittr)\n\n\n|&gt;\nThe base pipe will use the output from the first function and use it as the input of the first argument in the second function. Below, we obtain the mpg variable from mtcars and pipe it in the mean() function.\n\nmtcars$mpg |&gt; mean()\n\n#&gt; [1] 20.09062\n\n\n\n\n%&gt;%\n\nUses\nMagrittr’s pipe is the equivalent of Base R’s pipe, with some extra functionality. Below we repeat the same code as before:\n\nmtcars$mpg %&gt;% mean()\n\n#&gt; [1] 20.09062\n\n\nAlternatively, we do not have to type the parenthesis in the second function:\n\nmtcars$mpg %&gt;% mean\n\n#&gt; [1] 20.09062\n\n\nBelow is another example where we will pipe the value 3 into the rep() with times=5, this will repeat the value 3 five times:\n\n3 %&gt;% rep(5)\n\n#&gt; [1] 3 3 3 3 3\n\n\nIf we are interested in piping the output to another argument other than the first argument, we can use the (.) placeholder in the second function to indicate which argument should take the previous output. Below, we repeat the vector c(1, 2) three times because the . is in the second argument:\n\n3 %&gt;% rep(c(1,2), .)\n\n#&gt; [1] 1 2 1 2 1 2\n\n\n\n\nCreating Unary Functions\nYou can use %&gt;% and . to create unary functions, a function with one argument, can be created. The following code will create a new function called logsqrt() which evaluates \\(\\sqrt{\\log(x)}\\):\n\nlogsqrt &lt;- . %&gt;% log(base = 10) %&gt;% sqrt\nlogsqrt(10000)\n\n#&gt; [1] 2\n\nsqrt(log10(10000))\n\n#&gt; [1] 2\n\n\n\n\n\n%$%\nThe exposition pipe will expose the named elements of an object or output to the following function. For example, we will pipe the mtcars into the lm() function. However, we will use the %$% pipe to access the variables in the data frame for the formula= argument without having to specify the data= argument:\n\nmtcars %$% lm(mpg ~ hp)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = mpg ~ hp)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           hp  \n#&gt;    30.09886     -0.06823\n\n\n\n\n%T&gt;%\nThe Tee pipe will pipe the contents of the previous function into the following function, but will retain the previous functions output instead of the current function. For example, we use the Tee pipe to push the results from the lm() function to print out the summary table, then use the same lm() function results to print out the model standard error:\n\nx_lm &lt;- mtcars %$% lm(mpg ~ hp) %T&gt;% \n  (\\(x) print(summary(x))) %T&gt;% \n  (\\(x) print(sigma(x)))\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = mpg ~ hp)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -5.7121 -2.1122 -0.8854  1.5819  8.2360 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 30.09886    1.63392  18.421  &lt; 2e-16 ***\n#&gt; hp          -0.06823    0.01012  -6.742 1.79e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.863 on 30 degrees of freedom\n#&gt; Multiple R-squared:  0.6024, Adjusted R-squared:  0.5892 \n#&gt; F-statistic: 45.46 on 1 and 30 DF,  p-value: 1.788e-07\n#&gt; \n#&gt; [1] 3.862962\n\n\n\n\n\nKeyboard Shortcuts\nBelow is a list of recommended keyboard shortcuts:\n\n\n\nShortcut\nWindows/Linux\nMac\n\n\n\n\n%&gt;%\nCtrl+Shift+M\nCmd+Shift+M\n\n\nRun Current Line\nCtrl+Enter\nCmd+Return\n\n\nRun Current Chunk\nCtrl+Shift+Enter\nCmd+Shift+Enter\n\n\nKnit Document\nCtrl+Shift+K\nCmd+Shift+K\n\n\nAdd Cursor Below\nCtrl+Alt+Down\nCmd+Alt+Down\n\n\nComment Line\nCtrl+Shift+C\nCmd+Shift+C\n\n\n\nIt is recommended to modify these keyboard shortcuts in RStudio\n\n\n\nShortcut\nWindows/Linux\nMac\n\n\n\n\n%in%\nCtrl+Shift+I\nCmd+Shift+I\n\n\n%$%\nCtrl+Shift+D\nCmd+Shift+D\n\n\n%T&gt;%\nCtrl+Shift+T\nCmd+Shift+T\n\n\n\nNote you will need to install the extraInserts package:\n\nremotes::install_github('konradzdeb/extraInserts')"
  },
  {
    "objectID": "posts/r_adv.html#footnotes",
    "href": "posts/r_adv.html#footnotes",
    "title": "Advanced R Programming",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nType this in the console to see what it is.↩︎\ninstall.packages(greekLetters)↩︎\nWe will need to use paste0() to combine the letters together.↩︎"
  },
  {
    "objectID": "posts/r_basics.html",
    "href": "posts/r_basics.html",
    "title": "Basic R Programming",
    "section": "",
    "text": "Modifiend from Statistical Computing\nThis page focuses on the basics of R programming. While most of your statistical analysis will be done with R functions, it is important to have an idea of what is going on. Additionally, we will cover other topics that you may or may not need to know. The topics we will cover are:"
  },
  {
    "objectID": "posts/r_basics.html#basic-calculations",
    "href": "posts/r_basics.html#basic-calculations",
    "title": "Basic R Programming",
    "section": "Basic Calculations",
    "text": "Basic Calculations\nThis section focuses on the basic calculation that can be done in R. This is done by using different operators in R. The table below provides some of the basic operators R can use:\n\n\n\nOperator\nDescription\n\n\n\n\n+\nAddition\n\n\n-\nSubtraction\n\n\n*\nMultiplication\n\n\n/\nDivides\n\n\n^ or **\nExponent\n\n\n?\nHelp Documentation\n\n\n\n\nCalculator\n\nAddition\nTo add numbers in R, all you need to use the + operator. For example \\(2 + 2 = 4\\). When you type it in R you have:\n\n2 + 2\n\n#&gt; [1] 4\n\n\nWhen you ask R to perform a task, it prints out the result of the task. As we can see above, R prints out the number 4.\nTo add more than 2 numbers, you can simply just type it in.\n\n2 + 2 + 2\n\n#&gt; [1] 6\n\n\nThis provides the number 6.\n\n\nSubtraction\nTo subtract numbers, you need to use the - operator. Try 4 - 2:\n\n4 - 2\n\n#&gt; [1] 2\n\n\nTry 4 - 6 - 4\n\n4 - 6 - 4\n\n#&gt; [1] -6\n\n\nNotice that you get a negative number.\nNow try 4 + 4 - 2 + 8:\n\n4 + 4 - 2 + 8\n\n#&gt; [1] 14\n\n\n\n\nMultiplication\nTo multiply numbers, you will need to use the * operator. Try 4 * 4:\n\n4 * 4\n\n#&gt; [1] 16\n\n\n\n\nDivision\nTo divide numbers, you can use the / operator. Try 9 / 3:\n\n9 / 3\n\n#&gt; [1] 3\n\n\n\n\nExponents\nTo exponentiate a number to the power of another number, you can use the ^ operator. Try 2^5:\n\n2^5\n\n#&gt; [1] 32\n\n\nIf you want to find \\(e^2\\), you will use the exp() function. Try exp(2):\n\nexp(2)\n\n#&gt; [1] 7.389056\n\n\n\n\nRoots\nTo take the n-th root of a value, use the ^ operator with the / operator to take the n-th root. For example, to take \\(\\sqrt[5]{35}\\), type 32^(1/5):\n\n32^(1/5)\n\n#&gt; [1] 2\n\n\n\n\nLogarithms\nTo take the natural logarithm of a value, you will use the log() function. Try log(5):\n\nlog(5)\n\n#&gt; [1] 1.609438\n\n\nIf you want to take the logarithm of a different base, you will use the log() function with base argument. We will discuss this more in Section 3.\n\n\nPractice\nUse the code console below to attempt other arithmetic operations such as \\(\\ln(e^{23}) + \\sin(2\\pi) - 54/9*(3-8)^2\\):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nComparing Numbers\nAnother important part of R is comparing numbers. When you compare two numbers, R will tell if the statement is TRUE or FALSE. Below are the different comparisons you can make:\n\n\n\nOperator\nDescription\n\n\n\n\n&gt;\nGreater Than\n\n\n&lt;\nLess Than\n\n\n&gt;=\nGreater than or equal\n\n\n&lt;=\nLess than or equal\n\n\n==\nEquals\n\n\n!=\nNot Equals\n\n\n\n\nLess than/Greater than\nTo check if one number is less than or greater than another number, you will use the &gt; or &lt; operators. Try 5 &gt; 4:\n\n5 &gt; 4\n\n#&gt; [1] TRUE\n\n\nNotice that R states it’s true. It evaluates the expression and tells you if it’s true or not. Try 5 &lt; 4:\n\n5 &lt; 4\n\n#&gt; [1] FALSE\n\n\nNotice that R tells you it is false.\n\n\nLess than or equal to/Greater than or equal to\nTo check if one number is less than or equal to/greater than or equal to another number, you will use the &gt;= or &lt;= operators. Try 5 &gt;= 5:\n\n5 &gt;= 5\n\n#&gt; [1] TRUE\n\n\nTry 5 &gt;= 4:\n\n5 &gt;= 4\n\n#&gt; [1] TRUE\n\n\nTry 5 &lt;= 4\n\n5 &lt;= 4\n\n#&gt; [1] FALSE\n\n\n\n\nEquals and Not Equals\nTo check if 2 numbers are equal to each other, you can use the == operator. Try 3 == 3:\n\n3 == 3\n\n#&gt; [1] TRUE\n\n\nTry 4 == 3\n\n3 == 4\n\n#&gt; [1] FALSE\n\n\nAnother way to see if 2 numbers are not equal to each other, you can use the !=. Try 3 != 4:\n\n3 != 4\n\n#&gt; [1] TRUE\n\n\nTry 3 != 3:\n\n3 != 3\n\n#&gt; [1] FALSE\n\n\nYou may be asking why use != instead of ==. They both provides similar results. Well the reason is that you may need the TRUE output for analysis. One is only true when they are equal, while the other is true when they are not equal.\nIn general, the ! operator means not or opposite. It can be used to change an TRUE to a FALSE and vice-versa.\n\n\n\nHelp\nThe last operator we will discuss is the help operator ?. If you want to know more about anything we talked about you can type ? in front of a function and a help page will pop-up in your browser or in RStudio’s ‘Help’ tab. For example you can type ?Arithmetic or ?Comparison, to review what we talked about. For other operators we didn’t talk about use ?assignOps and ?Logic."
  },
  {
    "objectID": "posts/r_basics.html#types-of-data",
    "href": "posts/r_basics.html#types-of-data",
    "title": "Basic R Programming",
    "section": "Types of Data",
    "text": "Types of Data\nIn R, the type of data, also known as class, we are using dictates how the programming works. For the most part, users will use numeric, logical, POSIX and character data types. Other types of data you may encounter are complex and raw. To obtain more information on them, use the ? operator.\n\nNumeric\nThe numeric class is the data that are numbers. Almost every analysis that you use will be based on the numeric class. To check if you have a numeric class, you just need to use the is.numeric() function. For example, try is.numeric(5):\n\nis.numeric(5)\n\n#&gt; [1] TRUE\n\n\nNumeric classes are essentially double and integer types of data. For example a double data is essentially a number with decimal value. An integer data are whole numbers. Try is.numeric(5.63), is.double(5.63) and is.integer(5.63):\n\nis.numeric(5.63)\n\n#&gt; [1] TRUE\n\nis.double(5.63)\n\n#&gt; [1] TRUE\n\nis.integer(5.63)\n\n#&gt; [1] FALSE\n\n\nNotice how the value \\(5.63\\) is a numeric and double but not integer. Now let’s try is.numeric(7), is.double(7) and is.integer(7):\n\nis.numeric(7)\n\n#&gt; [1] TRUE\n\nis.double(7)\n\n#&gt; [1] TRUE\n\nis.integer(7)\n\n#&gt; [1] FALSE\n\n\nNotice how the value \\(7\\) is also considered a numeric and double but not integer. This is because typing a whole number will be stored as a double. However, if we need to store an integer, we will need to type the letter “L” after the number. Try is.numeric(7L), is.double(7L), and is.integer(7L):\n\nis.numeric(7L)\n\n#&gt; [1] TRUE\n\nis.double(7L)\n\n#&gt; [1] FALSE\n\nis.integer(7L)\n\n#&gt; [1] TRUE\n\n\n\n\nLogical\nA logical class are data where the only value is TRUE or FALSE. Sometimes the data is coded as 1 for TRUE and 0 for FALSE. The data may also be coded as T or F. To check if data belongs in the logical class, you will need the is.logical() function. Try is.logical(3 &lt; 4):\n\nis.logical(3 &lt; 4)\n\n#&gt; [1] TRUE\n\n\nThis is same comparison from Section 1.2. The output was TRUE. Now R is checking whether the output is of a logical class. Since it it, R returns TRUE. Now try is.logical(3 &gt; 4):\n\nis.logical(3 &gt; 4)\n\n#&gt; [1] TRUE\n\n\nThe output is TRUE as well even though the condition 3 &gt; 4 is FALSE. Since the output is a logical data type, it is a logical variable.\n\n\nPOSIX\nThe POSIX class are date-time data. Where the data value is a time component. The POSIX class can be very complex in how it is formatted. IF you would like to learn more try ?POSIXct or ?POSIClt. First, lets run Sys.time() to check what is today’s data and time:\n\nSys.time()\n\n#&gt; [1] \"2025-07-15 11:17:39 PDT\"\n\n\nNow lets check if its of POSIX class, you can use the class() function to figure out which class is it. Try class(Sys.time()):\n\nclass(Sys.time())\n\n#&gt; [1] \"POSIXct\" \"POSIXt\"\n\n\n\n\nCharacter\nA character value is where the data values follow a string format. Examples of character values are letters, words and even numbers. A character value is any value surrounded by quotation marks. For example, the phrase “Hello World!” is considered as one character value. Another example is if your data is coded with the actual words “yes” or “no”. To check if you have character data, use the is.character() function. Try is.character(\"Hello World!\"):\n\nis.character(\"Hello World!\")\n\n#&gt; [1] TRUE\n\n\nNotice that the output says TRUE. Character values can be created with single quotations. Try is.character('Hello World!'):\n\nis.character('Hello World!')\n\n#&gt; [1] TRUE\n\n\n\n\nComplex Numbers\nComplex numbers are data values where there is a real component and an imaginary component. The imaginary component is a number multiplied by \\(i=\\sqrt{-1}\\). To create a complex number, use the complex() function. To check if a number is complex, use the is.complex() function. Try the following to create a complex number complex(1, 4, 5):\n\ncomplex(1, 4, 5)\n\n#&gt; [1] 4+5i\n\n\nNow try is.complex(complex(1, 4, 5)):\n\nis.complex(complex(1, 4, 5))\n\n#&gt; [1] TRUE\n\n\n\n\nRaw\nYou will probably never use raw data. I have never used raw data in R. To create a raw value, use the raw() or charToRaw() functions. Try charToRaw('Hello World!'):\n\ncharToRaw('Hello World!')\n\n#&gt;  [1] 48 65 6c 6c 6f 20 57 6f 72 6c 64 21\n\n\nTo check if you have raw data, use the is.raw() function. Try is.raw(charToRaw('Hello World!')):\n\nis.raw(charToRaw('Hello World!'))\n\n#&gt; [1] TRUE\n\n\n\n\nMissing\nThe last data class in R is missing data. The table below provides a brief introduction of the different types of missing data\n\n\n\n\n\n\n\n\nValue\nDescription\nFunctions\n\n\n\n\nNULL\nThese are values indicating an object is empty. Often used for functions with values that are undefined.\nis.null()\n\n\nNA\nStands for “Not Available”, used to indicate that the value is missing in the data.\nis.na()\n\n\nNaN\nStands for “Not an Number”. Used to indicate a missing number.\nis.nan()\n\n\nInf and -Inf\nIndicating an extremely large value or a value divided by 0.\nis.infinite()"
  },
  {
    "objectID": "posts/r_basics.html#sec-r-functions",
    "href": "posts/r_basics.html#sec-r-functions",
    "title": "Basic R Programming",
    "section": "R Functions",
    "text": "R Functions\nAn R function is the procedure that R will execute to certain data. For example, the log(x) is an R function. It takes the value x and provides you the natural logarithm. Here x is known as an argument which needs to be specified to us the log() function. Find the log(x = 5)\n\nlog(x = 5)\n\n#&gt; [1] 1.609438\n\n\nAnother argument for the log() function is the base argument. With the previous code, we did not specify the base argument, so R makes the base argument equal to the number \\(e\\). If you want to use the common log with base 10, you will need to set the base argument equal to 10.\nTry log(x = 5, base = 10)\n\nlog(x = 5, base = 10)\n\n#&gt; [1] 0.69897\n\n\nNow try log(5,10)\n\nlog(5,10)\n\n#&gt; [1] 0.69897\n\n\nNotice that it provides the same value. This is because R can set arguments based on the values position in the function, regardless if the arguments are specified. For log(5,10), R thinks that 5 corresponds to the first argument x and 10 is the second argument base.\nTo learn more about a functions, use the ? operator on the function: ?log."
  },
  {
    "objectID": "posts/r_basics.html#sec-r-objects",
    "href": "posts/r_basics.html#sec-r-objects",
    "title": "Basic R Programming",
    "section": "R Objects",
    "text": "R Objects\nR objects are where most of your data will be stored. An R object can be thought of as a container of data. Each object will share some sort of characteristics that will make the unique for different types of analysis.\n\nAssigning objects\nTo create an R object, all we need to do is assign data to a variable. The variable is the name of the R object. it can be called anything, but you can only use alphanumeric values, underscore, and periods. To assign a value to a variable, use the &lt;- operator. This is known a left assignment. Kinda like an arrow pointing left. Try assigning 9 to ‘x’ (x &lt;- 9):\n\nx &lt;- 9\n\nTo see if x contains 9, type x in the console:\n\nx\n\n#&gt; [1] 9\n\n\nNow x can be treated as data and we can perform data analysis on it. For example, try squaring it:\n\nx^2\n\n#&gt; [1] 81\n\n\nYou can use any mathematical operation from the previous sections. Try some other operations and see what happens.\nThe output R prints out can be stored in a variable using the asign operator, &lt;-. Try storing x^3 in a variable called x_cubed:\n\nx_cubed &lt;- x^3\n\nTo see what is stored in x_cubed you can either type x_cubed in the console or use the print() function with x_cubed inside the parenthesis.\n\nx_cubed\n\n#&gt; [1] 729\n\nprint(x_cubed)\n\n#&gt; [1] 729\n\n\n\n\nVectors\nA vector is a set data values of a certain length. The R object x is considered as a numerical vector (because it contains a number) with the length 1. To check, try is.numeric(x) and is.vector(x):\n\nis.numeric(x)\n\n#&gt; [1] TRUE\n\nis.vector(x)\n\n#&gt; [1] TRUE\n\n\nNow let’s create a logical vector that contains 4 elements (have it follow this sequence: T, F, T, F) and assign it to y. To create a vector use the c()1 function and type all the values and separating them with columns. Type y &lt;- c(T, F, T, F):\n\ny &lt;- c(T, F, T, F)\n\nNow, lets see how y looks like. Type y:\n\ny\n\n#&gt; [1]  TRUE FALSE  TRUE FALSE\n\n\nNow lets see if it’s a logical vector:\n\nis.logical(y)\n\n#&gt; [1] TRUE\n\nis.vector(y)\n\n#&gt; [1] TRUE\n\n\nFortunately, this vector is really small to count how many elements it has, but what if the vector is really large? To find out how many elements a vector has, use the length() function. Try length(y):\n\nlength(y)\n\n#&gt; [1] 4\n\n\n\n\nMatrices\nA matrix can be thought as a square or rectangular grid of data values. This grid can be constructed can be any size. Similar to vectors they must contain the same data type. The size of a matrix is usually denoted as \\(n\\times k\\), where \\(n\\) represents the number of rows and \\(k\\) represents the number of columns. To get a rough idea of how a matrix may look like, type matrix(rep(1,12), nrow = 4, ncol = 3)2:\n\nmatrix(rep(1, 12), nrow = 4, ncol = 3)\n\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    1    1\n#&gt; [2,]    1    1    1\n#&gt; [3,]    1    1    1\n#&gt; [4,]    1    1    1\n\n\nNotice that this is a \\(4\\times 3\\) matrix. Each element in the matrix has the value 1. Now try this matrix(rbinom(12,1.5), nrow = 4, ncol = 3)3:\n\nmatrix(rbinom(12, 1, .5), nrow = 4, ncol = 3)\n\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    1    0\n#&gt; [2,]    1    1    0\n#&gt; [3,]    1    0    1\n#&gt; [4,]    1    1    1\n\n\nYour matrix may look different, but that is to be expected. Notice that some elements in a matrix are 0’s and some are 1’s. Each element in a matrix can hold any value.\nAn alternate approach to creating matrices is with the use of rbind() and cbind() functions. Using 2 vectors, and matrices, of the same length, the rbind() will append the vectors together by each row. Similarly, the cbind() function will append vectors, and matrices, of the same length by columns.\n\nx &lt;- 1:4\ny &lt;- 5:8\nz &lt;- 9:12\ncbind(x, y, z)\n\n#&gt;      x y  z\n#&gt; [1,] 1 5  9\n#&gt; [2,] 2 6 10\n#&gt; [3,] 3 7 11\n#&gt; [4,] 4 8 12\n\nrbind(x, y, z)\n\n#&gt;   [,1] [,2] [,3] [,4]\n#&gt; x    1    2    3    4\n#&gt; y    5    6    7    8\n#&gt; z    9   10   11   12\n\n\nIf you want to create a matrix of a specific size without any data, you can use the matrix() function and only specify the nrow and ncol arguments. Here we are creating a \\(5\\times 11\\) empty matrix:\n\nmatrix(nrow = 5, ncol = 11)\n\n#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]\n#&gt; [1,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n#&gt; [2,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n#&gt; [3,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n#&gt; [4,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n#&gt; [5,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n\n\nLastly, if you need to find out the dimensions of a matrix, you can use dim() function on a matrix:\n\ndim(matrix(nrow = 5, ncol = 11))\n\n#&gt; [1]  5 11\n\n\nThis will return a vector of length 2 with the first element being the number of rows and the second element being the number of columns.\n\n\nArrays\nMatrices can be considered as a 2-dimensional block of numbers. An array is an n-dimensional block of numbers. While you may never need to use an array for data analysis. It may come in handy when programming by hand. To create an array, use the array() function. Below is an example of a \\(3 \\times 3 \\times 3\\) with the numbers 1, 2, and 3 representing the 3rd dimension stored in an R object called first_array4.\n\n(first_array &lt;- array(c(rep(1, 9), rep(2, 9), rep(3, 9)),\n                      dim=c(3,3,3)))\n\n#&gt; , , 1\n#&gt; \n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    1    1\n#&gt; [2,]    1    1    1\n#&gt; [3,]    1    1    1\n#&gt; \n#&gt; , , 2\n#&gt; \n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    2    2    2\n#&gt; [2,]    2    2    2\n#&gt; [3,]    2    2    2\n#&gt; \n#&gt; , , 3\n#&gt; \n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    3    3    3\n#&gt; [2,]    3    3    3\n#&gt; [3,]    3    3    3\n\n\n\n\nData Frames\nData frames are similar to data set that you may encounter in an excel file. However, there are a couple of differences. First, each row represents an observation, and each column represents a characteristic of the observation. Additionally, each column in a data frame will be the same data type. To get an idea of what a data frame looks like, try head(iris) 5:\n\nhead(iris)\n\n\n  \n\n\n\nIn the data frame, the rows indicate a specific observation and the columns are the values of a variable. In terms of the iris data set, we can see that row 1 is a specific flower that has a sepal length of 5.1. We can also see that flower 1 has other characteristics such as sepal width and petal length. Lastly, there are results for the other flowers.\nNow try tail(iris):\n\ntail(iris)\n\n\n  \n\n\n\nThe tail() function provides the last 6 rows of the data frame.\nLastly, if you are interested in viewing a specific variable (column) from a data frame, you can use the $ operator to specify which variable from a specific data frame. For example, if we are interested in observing the Sepal.Length variable from the iris data frame, we will type iris$Sepal.Length:\n\niris$Sepal.Length\n\n#&gt;   [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1\n#&gt;  [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0\n#&gt;  [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5\n#&gt;  [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1\n#&gt;  [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5\n#&gt;  [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3\n#&gt; [109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2\n#&gt; [127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8\n#&gt; [145] 6.7 6.7 6.3 6.5 6.2 5.9\n\n\n\n\nLists\nTo me a list is just a container that you can store practically anything. It is compiled of elements, where each element contains an R object. For example, the first element of a list may contain a data frame, the second element may contain a vector, and the third element may contain another list. It is just a way to store things.\nTo create a list, use the list() function. Create a list compiled of first element with the mtcars data set, second element with a vector of zeros of size 4, and a matrix \\(3 \\times 3\\) identity matrix6. Store the list in an object called list_one:\n\nlist_one &lt;- list(mtcars, rep(0, 4),\n                 diag(rep(1, 3)))\n\nType list_one to see what pops out:\n\nlist_one\n\n#&gt; [[1]]\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; [[3]]\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    0    0\n#&gt; [2,]    0    1    0\n#&gt; [3,]    0    0    1\n\n\nEach element in the list is labeled as a number. It is more useful to have the elements named. An element is named by typing the name in quotes followed by the = symbol before your object in the list() function (mtcars=mtcars).\n\nlist_one &lt;- list(mtcars = mtcars,\n                 vector = rep(0, 4),\n                 identity = diag(rep(1, 3)))\n\nHere I am creating an object called list_one, where the first element is mtcars labeled mtcars, the second element is a vector of zeros labeled vector and the last element is the identity matrix labeled identity.’\nNow create a new list called list_two and store list_one labeled as list_one and first_array labeled as array.\n\n(list_two &lt;- list(list_one = list_one,\n                  array = first_array))\n\n#&gt; $list_one\n#&gt; $list_one$mtcars\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#&gt; \n#&gt; $list_one$vector\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $list_one$identity\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    0    0\n#&gt; [2,]    0    1    0\n#&gt; [3,]    0    0    1\n#&gt; \n#&gt; \n#&gt; $array\n#&gt; , , 1\n#&gt; \n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    1    1\n#&gt; [2,]    1    1    1\n#&gt; [3,]    1    1    1\n#&gt; \n#&gt; , , 2\n#&gt; \n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    2    2    2\n#&gt; [2,]    2    2    2\n#&gt; [3,]    2    2    2\n#&gt; \n#&gt; , , 3\n#&gt; \n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    3    3    3\n#&gt; [2,]    3    3    3\n#&gt; [3,]    3    3    3"
  },
  {
    "objectID": "posts/r_basics.html#load-data",
    "href": "posts/r_basics.html#load-data",
    "title": "Basic R Programming",
    "section": "Load Data",
    "text": "Load Data\nIn order to analyze data in R, we must load it into the R environment. This can be done in 2 ways, using the “Import Dataset” button in the “Environment” tab in RStudio or use R code.\n\nImporting Data Via RStudio\nThis is the most recommended way to import data in RStudio because it can provide R code that you can copy and paste in an R Script.\nTo begin choose the “Import Dataset” from the “Environment” tab in RStudio:\n\n\n\n\n\nAfterwards, select the type of file that you may need to import. If you select the “From Text (readr)…” option, a popup window will appear:\n\n\n\n\n\nYou can now navigate to the file that you may want to import with the “Browse…” button and modify it the process as needed with the options. Afterwards, you can copy the code in the lower-right hand corner and save it in an R script"
  },
  {
    "objectID": "posts/r_basics.html#footnotes",
    "href": "posts/r_basics.html#footnotes",
    "title": "Basic R Programming",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe c() function allows you to put any data type and as many values as you wish. The only condition of a vector is that it must be the same data type.↩︎\nThe function rep() creates a vector by repeating a value for a certain length. rep(1,12) creates a vector of length 12 with each element being 1. We use the nrow and ncol arguments in the function to specify the number of rows and columns, respectfully.↩︎\nThe rbinom() function generates binomial random variables and stores them in a vector. rbinom(12,1,5) This creates 12 random binomial numbers with parameter \\(n=1\\) and \\(p=0.5\\).↩︎\nNotice the code is surrounded by parenthesis. This tells R to store the array and print out the results. You can surround code with parenthesis every time you create an object to also print what is stored.↩︎\nThe head() function just tells R to only print the top few components of the data frame.↩︎\nAn identity matrix is a matrix where the diagonal elements are 1 and the non-diagonal elements are 0↩︎"
  },
  {
    "objectID": "posts/r_plot.html",
    "href": "posts/r_plot.html",
    "title": "Graphics",
    "section": "",
    "text": "Modifiend from Statistical Computing"
  },
  {
    "objectID": "posts/r_plot.html#base-r-plotting",
    "href": "posts/r_plot.html#base-r-plotting",
    "title": "Graphics",
    "section": "Base R Plotting",
    "text": "Base R Plotting\n\nIntroduction\nThis tutorial provides an introduction on how to create different graphics in R. For this tutorial, we will focus on plotting different components from the mtcars data set.\n\n\nContents\n\nBasic\nGrouping\nTweaking\n\n\n\nBasic Graphics\nHere we will use the built-in R functions to create different graphics. The main function that you will use is the plot(). It contains much of the functionality to create many different plots in R. Additionally, it works well for different classes of R objects. It will provide many important plots that you will need for a certain statistical analysis.\n\n\nScatter Plot\nLet’s first create a scatter plot for one variable using the mpg variable. This is done using the plot() and setting the first argument x to the vector.\n\nplot(mtcars$mpg)\n\n\n\n\n\n\n\n\nNotice that the x-axis is the index (which is not informative) and the y-axis is the mpg values.\nLet’s connect the points with a line. This is done by setting the type argument to \"l\".\n\nplot(mtcars$mpg, type = \"l\")\n\n\n\n\n\n\n\n\nLet’s add the points back to the plot and keep the lines. What we are going to do is first create the scatter plot as we did before, but we will also use the lines() function to add the lines. The lines() function needs the x argument which is a vector of points (mpg). The two lines of code must run together.\n\nplot(mtcars$mpg)\nlines(mtcars$mpg)\n\n\n\n\n\n\n\n\nNow, let’s create a more realistic scatter plot with 2 variables. This is done by specifying the y argument with another variable in addition to the x argument in the plot() funciton . Plot a scatter plot between mpg and disp.\n\nplot(mtcars$mpg,mtcars$disp)\n\n\n\n\n\n\n\n\nNow, let’s change the the axis labels and plot title. This is done by using the arguments main, xlab, and ylab. The main argument changes the title of the plot.\n\n\nHistogram\nTo create a histogram, use the hist() function. The hist() function only needs x argument which is numerical vector. Create a histogram with the mpg variable.\n\nhist(mtcars$mpg)\n\n\n\n\n\n\n\n\nIf you want to change the number of breaks in the histogram, use the breaks argument. Create a new histogram of the mpg variable with ten breaks.\n\nhist(mtcars$mpg, breaks = 10)\n\n\n\n\n\n\n\n\nThe above histograms provide frequencies instead of relative frequencies. If you want relative frequencies, use the freq argument and set it equal to FALSE in hist().\n\nhist(mtcars$mpg, freq = FALSE)\n\n\n\n\n\n\n\n\n\n\nDensity Plot\nA density plot can be used instead of a histogram. This is done by using the density() function to create an object containing the information to create density function. Then, use the plot() function to display the plot. The only argument the density() function needs is x which is the data to be used. Create a density plot the mpg variable.\n\nplot(density(mtcars$mpg))\n\n\n\n\n\n\n\n\nNow, if we want to overlay the density function over a histogram, use the lines() function with the output from the density() function as its main input. First create the histogram using the hist() function and setting the freq argument to FALSE. Then use the lines() function to overlay the density. Make sure to run both lines together.\n\nhist(mtcars$mpg, freq = FALSE)\nlines(density(mtcars$mpg))\n\n\n\n\n\n\n\n\n\n\nBox Plots\nA commonly used plot to display relevant statistics is the box plot. To create a box plot use the boxplot() argument. The function only needs the x argument which specifies the data to create the box plot. Use the box plot function to create a box plot on for the variable mpg.\n\nboxplot(mtcars$mpg)\n\n\n\n\n\n\n\n\nIf you want to make the box plot horizontal, use horizontal and set it equal to TRUE.\n\nboxplot(mtcars$mpg, horizontal = TRUE)\n\n\n\n\n\n\n\n\n\n\nBar Chart\nA histogram shows you the frequency for a continuous variable. A bar chart will show you the frequency of a categorical or discrete variable. To create a bar chart, use the barplot() function. The main argument it needs is the height argument which needs to be an object from the table() function. Create a bar chart for the cyl variable.\n\nbarplot(table(mtcars$cyl))\n\n\n\n\n\n\n\n\n\n\nPie Chart\nWhile I do not recommend using a pie chart, R is capable of creating one using the pie() function. It only needs the x argument which is a vector numerical quantities. This could be the output from the table() function. Create a pie chart with the cyl variable.\n\npie(table(mtcars$cyl))\n\n\n\n\n\n\n\n\n\n\nGrouping\nSimilar to obtaining statistics for certain groups, plots can be grouped to reveal certain trends. We will look at a couple of methods to visualize different groups.\n\nOne Variable Grouping\nTwo ways to display groups is by using color coding or panels. I will show you what I think is the best way to group variables. There may be better ways to do this, such as using the ggplot2 package. Before we begin, create three new R objects that are a subset of the mtcars data set into 3 different data sets with for the three different values of the cyl variable: “4”, “6”, and “8”. use the subset() function to create the different data sets. Name the new R objects mtcars_4, mtcars_6, and mtcars_8, respectively.\n\nmtcars_4 &lt;- subset(mtcars, cyl == 4)\nmtcars_6 &lt;- subset(mtcars, cyl == 6)\nmtcars_8 &lt;- subset(mtcars, cyl == 8)\n\n\nScatter Plot\nTo create different colors points for their respective label associated cyl variable. First create a base scatter plot using the plot() function to set up the plot. Then one by one, overlay a set of new points on the base plot using the points() function. The first two arguments should be the vectors of data from their respective R object subset. Also, use the col argument to change the color of the points. The col argument takes either a string or a number.\n\nplot(mtcars$mpg, mtcars$disp)\npoints(mtcars_4$mpg, mtcars_4$disp, col = \"red\")\npoints(mtcars_6$mpg, mtcars_6$disp, col = \"blue\")\npoints(mtcars_8$mpg, mtcars_8$disp, col = \"green\")\n\n\n\n\n\n\n\n\n\n\nHistogram\nNow, it us more difficult to overlay histograms on a plot to different colors. Therefore, a panel approach may be more beneficial. This can be done by setting up R to plot a grid of plots. To do this, use the par() to tell R how to set up the grid. Then use the mfrow argument, which is a vector of length two, to set up a grid. The mfrow argument usually has an input of c(ROWS,COLS) which states the number of rows and the number of columns. Once this is done, the next plots you create will be used to populate the grid.\n\npar(mfrow=c(1,3))\nhist(mtcars_4$mpg)\nhist(mtcars_6$mpg)\nhist(mtcars_8$mpg)\n\n\n\n\n\n\n\n\nEvery time you use the par() function, it will change how graphics are created in an R session. Therefore, all your plots will follow the new graphic parameters. You will need to reset it by typing dev.off().\n\n\nBar Chart\nTo visualize two categorical variables, we can use a color-coded bar chart to compare the frequencies of the categories. This is simple to do with the barplot() function. First, use the table() function to create a cross-tabulation of the frequencies for two variables. Then use the boxplot() function to visualize both variables. Then use legend argument to create a label when the bar chart is color-coded. Additionally, use the beside argument to change how the plot looks. Use the code below to compare the variables cyl and am variable.\n\nbarplot(table(mtcars$cyl, mtcars$am), beside = TRUE, legend = rownames(table(mtcars$cyl, mtcars$am)))\n\n\n\n\n\n\n\n\nNotice that I use the rownames() function to label the legend.\n\n\n\n\nTweaking\n\nLabels\nThe main tweaking of plots I will talk about is changing the the axis label and titles. For the most part, each function allows you to use the main, xlab, and ylab arguments. The main allows you to change the title. The xlab and ylab arguments allow you to change the labels for the x-axis and y-axis, respectively. Create a scatter plot for the variables mpg and disp and change the labels.\n\nplot(mtcars$mpg, mtcars$disp, main = \"MPG vs Displacement\", xlab = \"MPG\", ylab = \"Displacement\")"
  },
  {
    "objectID": "posts/r_plot.html#ggplot2",
    "href": "posts/r_plot.html#ggplot2",
    "title": "Graphics",
    "section": "ggplot2",
    "text": "ggplot2\n\nIntroduction\nThe ggplot2 package provides a set of functions to create different graphics. For more information on plotting in ggplot2, please visit the this excellent resource. Here we will discuss some of the basics to the ggplot2. From my perspective, ggplot2 creates a plot by adding layers to a base plot. The syntax is designed for you to change different components of a plot in an intuitive manner. For this tutorial, we will focus on plotting different components from the mpg data set.\n\nContents\n\nBasic\nGrouping\nThemes/Tweaking\n\n\n\n\nBasics\nTo begin, the ggplot2 package really works well when you are using data frames. If you have any output that you want to plot, convert into to a data frame. Once we have our data set, the first thing you would want to do is specify the main components of your base plot. This will be what will be plotted on your x-axis, and what will be plotted on your y-axis. Next, you will create the the type of plot. Lastly, you will add different layers to tweak the plot for your needs. This can be changing the layout or even overlaying another plot. The ggplot2 package provides you with tools to do almost everything you need to create a plot easily.\nBefore we begin plotting, load ggplot2 in R.\n\nlibrary(ggplot2)\n\nNow, when we create a base plot, we will use the ggplot() function. This will initialize the data that we need to use with the data argument and how to map it on the x and y axis with the mapping argument. The mapping argument uses the aes() function which constructs the mapping mechanism for the base plot. The aes() function requires the x argument and optionally uses the y argument to set which values represents the x and y axis. The aes() function also accepts other arguments for grouping or other aesthetics.\nBefore we begin, create a new variable in mtcars called ind and place a numeric vector which contains integers from 1 to 32.\n\nmtcars$ind &lt;- c(1:32)\n\nNow, let’s create the base plot and assign it to gg_1. Use the ggplot() function and set mtcars as its data and set x to ind and y = mpg.\n\ngg_1 &lt;- ggplot(mtcars, aes(ind, mpg))\n\nThis base plot is now used to create certain plots. Plots are created by adding functions to the base plot. This is done by using the + operator and then a specific ggplot2 function. Below we will go over some of the functions necessary.\n\n\nScatter Plot\nTo create a scatter plot in ggplot2, add the geom_point() function to the base plot. You do not need to specify any arguments in the function. Create a scatter plot to gg_1\n\ngg_1 + geom_point()\n\n\n\n\n\n\n\n\nIf we want to put lines instead of points, we will need to use the geom_point() function. Change the points to a line.\n\ngg_1 + geom_line()\n\n\n\n\n\n\n\n\nTo overlay points to the plot, add geom_point() as well as geom_line(). Add points to the plot above.\n\ngg_1 + geom_point() + geom_line()\n\n\n\n\n\n\n\n\nTo create a 2 variable scatter plot. You will just need to specify the x and y arguments in the aes() function. Create a base plot using the mtcars data set and use the mpg and disp as the x and y variables, respectively, and assign in it to gg_2\n\ngg_2 &lt;- ggplot(mtcars, aes(mpg, disp))\n\nNow create a scatter plot using gg_2.\n\ngg_2 + geom_point()\n\n\n\n\n\n\n\n\n\n\nHistogram and Density Plot\nTo create a histogram and density plots, create a base plot and specify the variable of interest in the aes() function, only specify one variable. Create a base plot using the mtcars data set and the mpg variable. Assign it to gg_3.\n\ngg_3 &lt;- ggplot(mtcars, aes(mpg))\n\nTo create a histogram, use the geom_histogram() function.\n\ngg_3 + geom_histogram()\n\n\n\n\n\n\n\n\nThe above plot shows a histogram, but the number of bins is quite large. We can change the bin width argument, binwidth, the geom_histogram() function. Change the bin width to seven.\n\ngg_3 + geom_histogram(binwidth = 7)\n\n\n\n\n\n\n\n\n\nDensity Plot\nTo create a density plot, use the geom_density() function. Create a density plot for the mpg variable.\n\ngg_3 + geom_density()\n\n\n\n\n\n\n\n\n\n\nBoth\nSimilar to adding lines and points in the same plot, you can add a histogram and a density plot by adding both the geom_histogram() and geom_density() functions. However, in the geom_histogram() function, you must add aes(y=after_stat(density)) to create a frequency histogram. Create a plot with a histogram and a density plot.\n\ngg_3 + geom_histogram(aes(y=after_stat(density)),bins=7) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\nBox Plots\nIf you need to create a box plot, use the stat_boxplot() function. Create a boxplot for the variable mpg. All you need to do is add stat_boxplot() function.\n\ngg_3 + stat_boxplot()\n\n\n\n\n\n\n\n\n\n\nBar Charts\nCreating a bar chart is similar to create a box plot. All you need to do is use the stat_count() or geom_bar() functions. First create a base plot using the mtcars data sets and the cyl variable for the mapping and assign it to gg_4.\n\ngg_4 &lt;- ggplot(mtcars, aes(cyl))\n\nNow create the bar plot by adding the stat_count() function.\n\ngg_4 + stat_count()\n\n\n\n\n\n\n\n\n\n\nGrouping\nThe ggplot2 package easily allows you to create plots from different groups. We will go over some of the arguments and functions to do this.\n\nOne Variable Grouping\n\nScatter Plot\nTo begin, we want to specify the grouping variable within the aes() function with the color argument. Additionally, the argument works best with a factor variable, so use the factor() function to create a factor variable. Create a base plot from the mtcars data set using mpg and disp for the x and y axis, respectively, and set the color argument equal to factor(cyl). Assign it the R object gg_5.\n\ngg_5 &lt;- ggplot(mtcars, aes(mpg, disp, color=factor(cyl)))\n\nOnce the base plot is created, ggplot2 will automatically group the data in the plots. Create the scatter plot from the base plot.\n\ngg_5 + geom_point()\n\n\n\n\n\n\n\n\nIf you want to change the shapes instead of the color, use the shape argument. Create a base plot from the mtcars data set using mpg, and disp for the x and y axis, respectively, and group it by cyl with the shape argument. Assign it the R object gg_6.\n\ngg_6 &lt;- ggplot(mtcars, aes(mpg, disp, shape=factor(cyl)))\ngg_6 + geom_point()\n\n\n\n\n\n\n\n\n\n\nHistograms\nHistograms can be grouped by different colors. This is done by using the fill argument within the aes() function in the base plot. Assign it the R object gg_7.\n\ngg_7 &lt;- ggplot(mtcars, aes(mpg, fill = factor(cyl)))\n\nNow create a histogram from the base plot gg_7.\n\ngg_7 + geom_histogram(bins = 6, alpha = 0.3)\n\n\n\n\n\n\n\n\nSometimes we would like to view the histogram on separate plots. The facet_wrap() function and the flact_grid() function allows this. Using either function, you do not need to specify the grouping factor in the aes() function. You will add facet_wrap() function to the plot. It needs a formula argument with the grouping variable. Using the R object gg_3 create side by side plots using the cyl variable. Remember to add geom_histogram().\n\ngg_3 + geom_histogram() + facet_wrap(~ cyl)\n\n\n\n\n\n\n\n\n\n\nDensity Plot\nSimilar to histograms, density plots can be grouped by variables the same way. Using gg_7, create color-coded density plots. All you need to do is add geom_density().\n\ngg_7 + geom_density(alpha=0.3)\n\n\n\n\n\n\n\n\nUsing gg_3, create side by side density plots. You need to do is add geom_density() and facet_wrap() to group with the cyl variable.\n\ngg_3 + geom_density() + facet_wrap( ~ cyl)\n\n\n\n\n\n\n\n\n\n\nBar Chart\nTo create a side by side bar plot, you can use the facet_wrap() function with a grouping variable. Using gg_4, create a side by side bar plot using vs as the grouping variable. Remember to add stat_count() as well.\n\ngg_4 + stat_count() + facet_wrap(~vs)\n\n\n\n\n\n\n\n\nIf you want to compare the bars from different group in one plot, you can use the fill argument from the aes() function. The fill argument just needs a factor variable (use factor()). First create a base plot using the data mtcars, variable cyl and grouping variable vs. Assign it to gg_8.\n\ngg_8 &lt;- ggplot(mtcars, aes(cyl, fill = factor(vs)))\n\nNow create a bar chart by adding stat_count().\n\ngg_8 + stat_count()\n\n\n\n\n\n\n\n\nIf you want to grouping bars to be side by side, use the position argument in the stat_count() function and set it equal to \"dodge\". Create the bar plot using the position = \"dodge\".\n\ngg_8 + stat_count(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\nThemes/Tweaking\nIn this section, we will talk about the basic tweaks and themes to a ggplot2 plot. However. ggplot2 is much more powerful and can do much more. Before we begin, lets look at object gg_9 to understand the plot. To view a plot, use the plot() function.\n\nplot(gg_9)\n\n\n\n\n\n\n\n\n\nTitle\nTo change the title, add the ggtitle() function to the plot. Put the new title in quotes as the first argument. Change the title for gg_9.\n\ngg_9 + ggtitle(\"Scatter Plot\")\n\n\n\n\n\n\n\n\n\n\nAxis\nChanging the labels for a plot, add the xlab() and ylab() functions, respectively. The first argument contains the phrase for the axis. Change the axis labels for gg_9.\n\ngg_9 + xlab(\"MPG\") + ylab(\"Displacement\")\n\n\n\n\n\n\n\n\n\n\nThemes\nIf you don’t like how the plot looks, ggplot2 has custom themes you can add to the plot to change it. These functions usually are formatted as theme_*() function, where the * indicates different possibilities. Change the theme of gg_9.\n\ngg_9 + theme_bw()\n\n\n\n\n\n\n\n\nAdditionally, you can change certain part of the theme using the theme() function. I encourage you to look at what are other possibilities.\n\n\n\nSaving plot\nIf you want to save the plot, use the ggsave() function. Read the help documentation for the functions capabilities."
  },
  {
    "objectID": "posts/rstudio.html",
    "href": "posts/rstudio.html",
    "title": "R and RStudio",
    "section": "",
    "text": "R is a programming language that allows users to compute statistics and graphics. It is based on S and is a GNU Project. It has several built-in function to compute statistics with ease, as well as allowing users to build their own functions to be executed."
  },
  {
    "objectID": "posts/rstudio.html#installing-r",
    "href": "posts/rstudio.html#installing-r",
    "title": "R and RStudio",
    "section": "Installing R",
    "text": "Installing R\nR can be installed from the R-Project with these general instructions:\n\nGo to R’s website\nSelect download R in the first paragraph\nChoose 0-Cloud to automatically choose the closes mirror.\nSelect and follow the instructions for the respective operating system"
  },
  {
    "objectID": "posts/rstudio.html#installation",
    "href": "posts/rstudio.html#installation",
    "title": "R and RStudio",
    "section": "Installation",
    "text": "Installation\nYou can download and install the open-source (free) version of RStudio here."
  },
  {
    "objectID": "posts/rstudio.html#start-up",
    "href": "posts/rstudio.html#start-up",
    "title": "R and RStudio",
    "section": "Start-up",
    "text": "Start-up\nOn start-up, RStudio will look like very similar to the image below:\n\n\n\n\n\nYou can see that there are 3 parts in RStudio, these are known as panes.\nAdditionally, we can add a fourth pane to RStudio for writing code in a text file. Choosing the white plus sign with a green border followed by a white document on the upper-right hand side:\n\n\n\n\n\nThis will open up a menu of text files that a user can choose to code in:\n\n\n\n\n\nThe “R Script” Button will open a standard R text file with the extension as “.R”. This is the text file that most R programmers used to save and execute code. This will make RStudio to look like this:\n\n\n\n\n\nNotice a new pane is created on the top-left that allows you to write R code in a script. This script is also connected to the R console below which will allow you to send lines of code from the script to the console to be executed (also known as REPL)."
  },
  {
    "objectID": "posts/rstudio.html#global-options",
    "href": "posts/rstudio.html#global-options",
    "title": "R and RStudio",
    "section": "Global Options",
    "text": "Global Options\nIn this section, here are some recommended “Global Options” for users to set in RStudio. To begin, click on Tools ➜ Global Options from the top-menu. The following window should open:\n\n\n\n\n\nThe window allows you to make several changes in RStudio that will make your experience better. Here is a list of items that are recommended for users to change:\n\nR General\n\nMake sure “Restore .RData into workspace at startup:” is unchecked (Highly Recommended1)\nSet “Save workspce to .RData on exit:” to “Never” (Highly Recommended)\n\n\n\n\n\n\n\n\nCode\n\n“Use native pipe operator |&gt;” is recommended2 (Optional)\n\n\n\n\n\n\n\n\nAppearance\n\nIn the “Editor theme:” box, choose a setting that you will prefer to work in (Optional)\n\n\n\n\n\n\n\n\nPane Layout (Optional)\n\nChange the pane layout to have the “Console” on the top-right corner\nAdd all components (checkmark) to the lower-right corner except for “History” and “Connections”\n\n\nThis will allow for you to expand the “Source” (script) to be expanded for the entire left hand side. It will allow you to view more code at one time.\nRStudio will look more like this:\n\n\n\n\n\nWith the expanded script:"
  },
  {
    "objectID": "posts/rstudio.html#source-console-and-plots",
    "href": "posts/rstudio.html#source-console-and-plots",
    "title": "R and RStudio",
    "section": "Source, Console and Plots",
    "text": "Source, Console and Plots\nThe source pane allows you to write an R script for analysis. Below x &lt;- mtcars is written (top-left) and executed to R (top-right). Afterwards the “Environment” Tab in the lower right pane now how x. The “Environment” tab displays which R objects were created and available to use for further analysis.\n\n\n\n\n\nSince x is a data frame, clicking on x from the “Environment” tab will open a new tab in the Source pane containing the data set:\n\n\n\n\n\nIf we create an object that is a vector ( y &lt;- 4 as pictured below), the “Environment” tab now shows a new object as a value.\n\n\n\n\n\nIf a plot is created (plot(mtcars$mpg)), a plot will be displayed in the “Plots” tab in the lower-right pane.\n\n\n\n\n\nThe lower right-pane also contains other useful features such as access to your computer’s file directory:\n\n\n\n\n\nAccess to installed packages:\n\n\n\n\n\nAnd access to help documentation:"
  },
  {
    "objectID": "posts/rstudio.html#footnotes",
    "href": "posts/rstudio.html#footnotes",
    "title": "R and RStudio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis will ensure that your environment is always recreated from the code you write and not from anything else. It increases reproducibility.↩︎\nThe native pipe does not require to have any packages installed. Additionally, it executes code slightly faster than %&gt;%.↩︎"
  },
  {
    "objectID": "posts/document.html",
    "href": "posts/document.html",
    "title": "Quarto Documents",
    "section": "",
    "text": "Modified from Statistical Computing"
  },
  {
    "objectID": "posts/document.html#introduction",
    "href": "posts/document.html#introduction",
    "title": "Quarto Documents",
    "section": "Introduction",
    "text": "Introduction\nQuarto is a file type used to create technical reports while including either R and/or Python code, or other programming languages, and output the results in a document. A qmd1 file is a fancy text Script containing extra capabilities to create scientific documentation. Additionally, qmd files allow for citations, footnotes, mathematical expressions, links, and much more. Once the document is finished, it can be rendered to a word file, pdf, html file, and much more. Quarto is the considered the next generation of RMarkdown.\nThis document is created using a qmd file. You can view the source code here"
  },
  {
    "objectID": "posts/document.html#anatomy-of-a-quarto-document",
    "href": "posts/document.html#anatomy-of-a-quarto-document",
    "title": "Quarto Documents",
    "section": "Anatomy of a Quarto Document",
    "text": "Anatomy of a Quarto Document\nThere are three main components in an qmd file: the YAML header, R code, and basic text.\nThe YAML header contains information on how to render the document. It is located at the beginning of the document surrounded by 3 dashes (---) above and below it. For starters, the YAML header will contain a ‘title’, ‘author’, ‘date’, and ‘output’ line.\nThe R code is located in a block known as chunks. A chunk tells RStudio to read the next lines as code. A chunk begins with three back ticks followed by {r} and ends with three back ticks. Everything in between the back ticks will be executed by R. In RStudio or Positron, a chunk can be inserted using the keyboard shortcut ctrl+alt+I or cmd+option+I.\nAn example of an R chunk is shown below:\n\n```{r}\nmean(mtcars$mpg)\n```\n\nThe R chunk will be rendered as below:\n\nmean(mtcars$mpg)\n\n#&gt; [1] 20.1\n\n\nNotice the chunk includes the code in a block followed by the output from the console.\nThe last component of an qmd document is the text. Write anywhere in the document, and it will be rendered as is."
  },
  {
    "objectID": "posts/document.html#chunk-options",
    "href": "posts/document.html#chunk-options",
    "title": "Quarto Documents",
    "section": "Chunk Options",
    "text": "Chunk Options\nR chunks have options that will alter how the code or the output is rendered. The chunk options can be set either globally to affect the entire qmd document or locally to affect only an individual chunk. For more information about chunk options, visit https://yihui.org/knitr/options/\n\nGlobal Chunk Options\nTo set global chunks options, add the two lines to YAML header:\n\n---\nknitr:\n  opts_chunk: \n---\n\nFollowed by the chunks and R options you want to set:\n\n---\nknitr:\n  opts_chunk:\n    eval: false\n    R.options:\n      digits: 2\n---\n\nA couple of recommended chunk options set globally are eval: false, and tidy: true. These options make rendering the document easier.\nR.Options: tells Quarto that the options R will be changed, and each line after alters options. digits: 2 indicates R to use 2 significant digits.\n\n\nLocal Chunk Options\nLocal chunk options can be used to control an individual chunk will behave. To control a specific chunk, place the option below the {r} identifier and use the #| chunk option indicator. An example is povided below:\n\n```{r}\n#| eval: false\n#| tidy: false\n\nmean(mtcars$mpg)\n```\n\nThe chunk option eval set to false tells Quarto to not evaluate the code within the chunk. Notice how the output was not printed the R chunk above. When we set eval to true, the output is printed:\n\n```{r}\n#| eval: true\nmean(mtcars$mpg)\n```\n\n#&gt; [1] 20.1\n\n\nThe echo option will control if the code within the chunk should be printed in the document. This next chunk contains #| echo: true:\n\nmean(mtcars$mpg)\n\n#&gt; [1] 20.1\n\n\nNow the chunk contains #| echo: false:\n\n\n#&gt; [1] 20.1\n\n\nThe R Code disappears.\nThere are chunk options for figures as well. A few options are fig-height, fig-width, fig-align, and fig-cap.\nThis chunk contains fig-height: 3.5; fig-width: 3.5; fig-align: left.\n\n```{r}\n#| eval: true\n#| fig-height: 3.5\n#| fig-width: 3.5\n#| fig-align: left\n\nplot(mtcars$mpg, mtcars$drat)\n```\n\n\n\n\n\n\n\n\nThe chunk options tells RStudio to create an image that is 3.5 inches in height and width, and align the image to the left.\nThe following chunk contains fig-height: 3.5; fig-width: 3.5; fig-align: left; fig-cap: \"This is a scatter plot of MTCARS' MPG and DRAT\"; label: fig-mtcars.\n\n```{r}\n#| eval: true\n#| fig-height: 3.5\n#| fig-width: 3.5\n#| fig-align: center\n#| fig-cap: \"This is a scatter plot of MTCARS' MPG and DRAT\"\n#| label: fig-mtcars\n\nplot(mtcars$mpg, mtcars$drat)\n```\n\n\n\n\n\n\n\nFigure 1: This is a scatter plot of MTCARS’ MPG and DRAT\n\n\n\n\n\nThe chunk adds a caption with fig-cap and reference label with label. The label of the plot can be referenced later in the document. Figure 1 can be referenced with @fig-mtcars.\n\n\nInline Code\nInstead of evaluating code in a chunk, code can evaluated in the text instead. For example, if we want to write the mean mpg in mtcars is 20.090625, one can type {r} mean(mtcars$mpg), surrounded by back ticks (`), instead of writing the entire number and risk of miscopying the results."
  },
  {
    "objectID": "posts/document.html#formatting",
    "href": "posts/document.html#formatting",
    "title": "Quarto Documents",
    "section": "Formatting",
    "text": "Formatting\nQmd files contain basic formatting capabilities. The use of the # followed by text creates a heading. Using two or more # symbols will create subheadings based on the number of #. A text is italicized by surrounding the text with one asterisk (*italicized*). A text is boldfaced by surrounding it with 2 asterisk (**boldfaced**).\nTo create an unordered list, use the - symbol at the beginning of each line, followed by a space. To create a sub-item, press the tab button (2 spaces), then the - symbol. Repeat this method for further sub-items.\n\nFirst Item\nSecond Item\n\nFirst Sub-Item\n\nFirst Sub-Sub-Item\n\nFirst Sub-Sub-Sub-Item\n\n\n\n\nTo created an ordered list, type the number followed by a period for each line. To create sub-lists, press the tab button twice and order them appropriately.\n\nFirst\nSecond\n\nFirst\nSecond\n\nFirst\nSecond\n\n\n\n\nA block quote is created with the &gt; symbol at the beginning of a line.\n\nQmd files allows a table to be constructed in 2 ways, manually or using a package such as the gt package. A table is manually created by using |, :, and -. The first line contains | and the column names in between. The second line contains |:-|:-| which indicates how the table is aligned. The location of : symbol just tells RStudio about the alignment. Below is the example code of Table 3:\n\n| Letter     |   Lowercase   |      Code     |  Uppercase |    Code    |\n|:-----------|:-------------:|:-------------:|:----------:|:----------:|\n| alpha      |    $\\alpha$   |    `\\alpha`   |     --     |     --     |\n| beta       |    $\\beta$    |    `\\beta`    |     --     |     --     |\n| gamma      |    $\\gamma$   |    `\\gamma`   |  $\\Gamma$  |  `\\Gamma`  |\n| delta      |    $\\delta$   |    `\\delta`   |  $\\Delta$  |  `\\Delta`  |\n| epsilon    |   $\\epsilon$  |   `\\epsilon`  |     --     |     --     |\n| zeta       |    $\\zeta$    |    `\\zeta`    |     --     |     --     |\n| eta        |     $\\eta$    |     `\\eta`    |     --     |     --     |\n| theta      |    $\\theta$   |    `\\theta`   |  $\\Theta$  |  `\\Theta`  |\n| iota       |    $\\iota$    |    `\\iota`    |     --     |     --     |\n| kappa      |    $\\kappa$   |    `\\kappa`   |     --     |     --     |\n| lambda     |   $\\lambda$   |   `\\lambda`   |  $\\Lambda$ |  `\\Lambda` |\n| mu         |     $\\mu$     |     `\\mu`     |     --     |     --     |\n| nu         |     $\\nu$     |     `\\nu`     |     --     |     --     |\n| xi         |     $\\xi$     |     `\\xi`     |    $\\Xi$   |    `\\Xi`   |\n| pi         |     $\\pi$     |     `\\pi`     |    $\\Pi$   |    `\\pi`   |\n| rho        |     $\\rho$    |     `\\rho`    |     --     |     --     |\n| sigma      |    $\\sigma$   |    `\\sigma`   |  $\\Sigma$  |  `\\Sigma`  |\n| tau        |     $\\tau$    |     `\\tau`    |     --     |     --     |\n| upsilon    |   $\\upsilon$  |   `\\upsilon`  | $\\Upsilon$ | `\\Upsilon` |\n| phi        |     $\\phi$    |     `\\phi`    |   $\\Phi$   |   `\\Phi`   |\n| chi        |     $\\chi$    |     `\\chi`    |     --     |     --     |\n| psi        |     $\\psi$    |     `\\psi`    |   $\\Psi$   |   `\\Psi`   |\n| omega      |    $\\omega$   |    `\\omega`   |  $\\Omega$  |  `\\Omega`  |\n| varepsilon | $\\varepsilon$ | `\\varepsilon` |     --     |     --     |\n\n: LaTeX syntax for greek letters. {#tbl-greektable}\n\nThe last line will adds a caption to the table and {#tbl-greektable} creates a label to reference the table in the text using @tbl-greektable.\nThe gt function from the gt package creates a table from a data frame or R object. Here is an example code to create a table from the first 6 rows of the mtcars dataset:\n\n```{r}\n#| label: tbl-mtcarsdata\n#| eval: true\n\nmtcars |&gt;\n    head() |&gt;\n    gt::gt() |&gt;\n    gt::tab_caption(\"The MTCARS Dataset\")\n```\n\n\n\n\n\n\n\n\nThe MTCARS Dataset\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\n21.0\n6\n160\n110\n3.90\n2.62\n16.5\n0\n1\n4\n4\n\n\n21.0\n6\n160\n110\n3.90\n2.88\n17.0\n0\n1\n4\n4\n\n\n22.8\n4\n108\n93\n3.85\n2.32\n18.6\n1\n1\n4\n1\n\n\n21.4\n6\n258\n110\n3.08\n3.21\n19.4\n1\n0\n3\n1\n\n\n18.7\n8\n360\n175\n3.15\n3.44\n17.0\n0\n0\n3\n2\n\n\n18.1\n6\n225\n105\n2.76\n3.46\n20.2\n1\n0\n3\n1\n\n\n\n\n\n\n\n\nTable 1: The MTCARS Dataset\n\n\n\n\nNotice that Table 1 is easily produced using the gt() function with a caption\nTable Table 1 is referenced by using the label created in the chunk and the @tbl-mtcarsdata. To install gt run the following line in your console:\n\ninstall.packages(\"gt\")"
  },
  {
    "objectID": "posts/document.html#citations-and-referneces",
    "href": "posts/document.html#citations-and-referneces",
    "title": "Quarto Documents",
    "section": "Citations and Referneces",
    "text": "Citations and Referneces\nQmd documents contains capabilities to add citations and a bibliography. For example, to cite this textbook (Mendenhall and Sincich 2012), use the @ symbol followed by a citation identifier from the .bib file surrounded by square brackets, [@mendenhallSecondCourseStatistics2012]. To cite your textbook again (2012) without the authors names, use a - sign in front of the @ symbol, [-@mendenhallSecondCourseStatistics2012]. To cite multiple books (Casella and Berger 1990; Rohatgi and Saleh 2015; Resnick 2014; Erich L. Lehmann and Casella 1998; E. L. Lehmann and Romano 2005), add each citation inside the square brackets with the @ symbol and separate them with semicolons, [@casellaStatisticalInference1990; @rohatgiIntroductionProbabilityStatistics2015; @resnickProbabilityPath2014; @lehmannTheoryPointEstimation1998; @lehmannTestingStatisticalHypotheses2005].\nThe references will be added automatically at the end of the document.\nIn order to use citations and references, the qmd file needs needs a .bib file containing all the information of the references. First, save the .bib file in the same folder (directory) as your qmd file. Then add the line bibliography: NAME.bib to the YAML header. Make any changes appropriately to the line, such as the name of the .bib file.\n\n.bib File\nThe .bib file is an ordinary text file containing “bib” entries with information about each reference. Below is an example bib entry about R:\n\n\n#&gt; @Manual{,\n#&gt;   title = {R: A Language and Environment for Statistical Computing},\n#&gt;   author = {{R Core Team}},\n#&gt;   organization = {R Foundation for Statistical Computing},\n#&gt;   address = {Vienna, Austria},\n#&gt;   year = {2025},\n#&gt;   url = {https://www.R-project.org/},\n#&gt; }\n\n\nCreating a .bib file is tedious; however, there are reference managers that can help. I recommend using Zotero, an open-source reference manager designed to import and manage citations. Once a citation is in Zotero, you can export your library as a .bib file. Make sure to check your references in Zotero for any mistakes."
  },
  {
    "objectID": "posts/document.html#math",
    "href": "posts/document.html#math",
    "title": "Quarto Documents",
    "section": "Math",
    "text": "Math\nQuarto is capable of writing mathematical formulas using LaTeX code. A mathematical symbol can be written inline using single $ signs. For example, $\\alpha$ is viewed as \\(\\alpha\\) in a document. To write mathematical formulas on its own line use $$. For example, $$Y=mX+b$$ is viewed as \\[Y=mX+b\\].\n\nMathematical Notation\n\n\n\nTable 2: LaTeX syntax for common examples.\n\n\n\n\n\nNotation\ncode\n\n\n\n\n\\(x=y\\)\n$x=y$\n\n\n\\(x&gt;y\\)\n$x&gt;y$\n\n\n\\(x&lt;y\\)\n$x&lt;y$\n\n\n\\(x\\geq y\\)\n$x\\geq y$\n\n\n\\(x\\leq y\\)\n$x\\leq y$\n\n\n\\(x^{y}\\)\n$x^{y}$\n\n\n\\(x_{y}\\)\n$x_{y}$\n\n\n\\(\\bar x\\)\n$\\bar x$\n\n\n\\(\\hat x\\)\n$\\hat x$\n\n\n\\(\\tilde x\\)\n$\\tilde x$\n\n\n\\(\\frac{x}{y}\\)\n$\\frac{x}{y}$\n\n\n\\(\\frac{\\partial x}{\\partial y}\\)\n$\\frac{\\partial x}{\\partial y}$\n\n\n\\(x\\in A\\)\n$x\\in A$\n\n\n\\(x\\subset A\\)\n$x\\subset A$\n\n\n\\(x\\subseteq A\\)\n$x\\subseteq A$\n\n\n\\(x\\cup A\\)\n$x\\cup A$\n\n\n\\(x\\cap A\\)\n$x\\cap A$\n\n\n\\(\\{1,2,3\\}\\)\n$\\{1,2,3\\}$\n\n\n\\(\\int_a^bf(x)dx\\)\n$\\int_a^bf(x)dx$\n\n\n\\(\\left\\{\\int_a^bf(x)dx\\right\\}\\)\n$\\left\\{\\int_a^bf(x)dx\\right\\}$\n\n\n\\(\\sum^n_{i=1}x_i\\)\n$\\sum^n_{i=1}x_i$\n\n\n\\(\\prod^n_{i=1}x_i\\)\n$\\prod^n_{i=1}x_i$\n\n\n\\(\\lim_{x\\to0}f(x)\\)\n$\\lim_{x\\to0}f(x)$\n\n\n\\(X\\sim \\Gamma(\\alpha,\\beta)\\)\n$X\\sim \\Gamma(\\alpha,\\beta)$\n\n\n\n\n\n\n\n\nGreek Letters\n\n\n\nTable 3: LaTeX syntax for greek letters.\n\n\n\n\n\nLetter\nLowercase\nCode\nUppercase\nCode\n\n\n\n\nalpha\n\\(\\alpha\\)\n\\alpha\n–\n–\n\n\nbeta\n\\(\\beta\\)\n\\beta\n–\n–\n\n\ngamma\n\\(\\gamma\\)\n\\gamma\n\\(\\Gamma\\)\n\\Gamma\n\n\ndelta\n\\(\\delta\\)\n\\delta\n\\(\\Delta\\)\n\\Delta\n\n\nepsilon\n\\(\\epsilon\\)\n\\epsilon\n–\n–\n\n\nzeta\n\\(\\zeta\\)\n\\zeta\n–\n–\n\n\neta\n\\(\\eta\\)\n\\eta\n–\n–\n\n\ntheta\n\\(\\theta\\)\n\\theta\n\\(\\Theta\\)\n\\Theta\n\n\niota\n\\(\\iota\\)\n\\iota\n–\n–\n\n\nkappa\n\\(\\kappa\\)\n\\kappa\n–\n–\n\n\nlambda\n\\(\\lambda\\)\n\\lambda\n\\(\\Lambda\\)\n\\Lambda\n\n\nmu\n\\(\\mu\\)\n\\mu\n–\n–\n\n\nnu\n\\(\\nu\\)\n\\nu\n–\n–\n\n\nxi\n\\(\\xi\\)\n\\xi\n\\(\\Xi\\)\n\\Xi\n\n\npi\n\\(\\pi\\)\n\\pi\n\\(\\Pi\\)\n\\pi\n\n\nrho\n\\(\\rho\\)\n\\rho\n–\n–\n\n\nsigma\n\\(\\sigma\\)\n\\sigma\n\\(\\Sigma\\)\n\\Sigma\n\n\ntau\n\\(\\tau\\)\n\\tau\n–\n–\n\n\nupsilon\n\\(\\upsilon\\)\n\\upsilon\n\\(\\Upsilon\\)\n\\Upsilon\n\n\nphi\n\\(\\phi\\)\n\\phi\n\\(\\Phi\\)\n\\Phi\n\n\nchi\n\\(\\chi\\)\n\\chi\n–\n–\n\n\npsi\n\\(\\psi\\)\n\\psi\n\\(\\Psi\\)\n\\Psi\n\n\nomega\n\\(\\omega\\)\n\\omega\n\\(\\Omega\\)\n\\Omega\n\n\nvarepsilon\n\\(\\varepsilon\\)\n\\varepsilon\n–\n–"
  },
  {
    "objectID": "posts/document.html#rendering-a-document",
    "href": "posts/document.html#rendering-a-document",
    "title": "Quarto Documents",
    "section": "Rendering a Document",
    "text": "Rendering a Document\nA qmd file can be rendered into either an html file, pdf document or word document. Rendering the qmd file to an html file or word document can be easily done using the knit button above. However, rendering the qmd file to a pdf document requires LaTeX to be installed. There are two methods to install LaTeX: from the LaTeX website or from R. I recommend installing the full LaTeX distribution from the https://www.latex-project.org/get/. This provides you with everything you may need. You can also install it from R:\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\nYou will only need to run these lines of code once and then you can render pdf documents easily.\n\nHTML\n\n---\nformat: html\n---\n\n\n\nPDF\n\n---\nformat: pdf\n---\n\n\n\nWord Document\n\n---\nformat: docx\n---"
  },
  {
    "objectID": "posts/document.html#resources-and-tips",
    "href": "posts/document.html#resources-and-tips",
    "title": "Quarto Documents",
    "section": "Resources and Tips",
    "text": "Resources and Tips\n\nQuarto\n\nQuarto\nMarkdown Basics\nFormats\n\n\n\nRMarkdown\n\nRStudio\nBookdown\n\n\n\nYAML\n\nUCLA Resource\nReproducible Research\nRMarkdown Crash Course\n\n\n\nTips\n\nRender your document often so it easier to identify problems with rendering\nThe Visual Mode in RStudio eases the process of creating a document and makes it more bearable.\nYAML is tricky with spacing. Make sure that spaces when indenting options. Also make sure that there are not extra spaces at the end of each line."
  },
  {
    "objectID": "posts/document.html#footnotes",
    "href": "posts/document.html#footnotes",
    "title": "Quarto Documents",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nQMD is the file extension to use the Quarto engine. For this document Quarto and QMD are used interchangeably.↩︎"
  },
  {
    "objectID": "posts/gc.html",
    "href": "posts/gc.html",
    "title": "Google Colab and Assignments",
    "section": "",
    "text": "Google Colaboratory (Colab) is an online service that provides both computing resources and a jupyter notebook environment in both R and Python. In this page, we will discuss how to create data science assignment with google colab and embedding it in Canvas."
  },
  {
    "objectID": "posts/gc.html#what-is-google-colab",
    "href": "posts/gc.html#what-is-google-colab",
    "title": "Google Colab and Assignments",
    "section": "What is Google Colab?",
    "text": "What is Google Colab?\nGoogle Colab is a free, cloud-based Jupyter notebook environment that allows you to execute R/Python code through a web browser. It provides free access to RAM/CPUs/GPUs/TPUs to complete computational tasks. It is designed for data science, machine learning, and education that is integradted with Google Drive for saving and sharing notebooks."
  },
  {
    "objectID": "posts/gc.html#creating-a-notebook-in-google-colab",
    "href": "posts/gc.html#creating-a-notebook-in-google-colab",
    "title": "Google Colab and Assignments",
    "section": "Creating a Notebook in Google Colab",
    "text": "Creating a Notebook in Google Colab\nThe simplest way to create a notebook in Google Colab is to go to your school’s Google Drive, click on the “New” button, click “More”, and click “Google Colaboratory”:\n\nThis will create a new tab in your browser that looks like this:\n\nYou can now create a notebook assignments with questions and code."
  },
  {
    "objectID": "posts/gc.html#google-colab-notebook",
    "href": "posts/gc.html#google-colab-notebook",
    "title": "Google Colab and Assignments",
    "section": "Google Colab Notebook",
    "text": "Google Colab Notebook\nIn a Google colab notebook, there are 3 main cells that you will have: text, code, and output cells.\nCode Cells:\n\nContaina executable code.\nOutput appears below the cell.\nCan be run individually or all at once.\n\nText Cells (Markdown Cells):\n\nContain formatted text (Markdown).\nUsed for explanations, documentation, etc.\n\nOutput Cells:\n\nAutomatically generated.\nDisplay results of code execution.\n\nThese cells will allow to create a notebook that both explains and executes data science projects."
  },
  {
    "objectID": "posts/gc.html#choosing-a-language",
    "href": "posts/gc.html#choosing-a-language",
    "title": "Google Colab and Assignments",
    "section": "Choosing a Language",
    "text": "Choosing a Language\nGoogle Colab will execute a notebook in 3 different languages seperately: Julia, R, and Python. To change the runtime (langauge) of a notebook, select the “Runtime” button, followed by “Change Runtime Type”:\n\nThe a pop-up window will appear. You can then select which language you may want to choose from:\n\nAfterwards, the notebook will only use the language you choose to execute the code cells."
  },
  {
    "objectID": "posts/gc.html#uploading-a-jupyter-notebook-to-google-colab",
    "href": "posts/gc.html#uploading-a-jupyter-notebook-to-google-colab",
    "title": "Google Colab and Assignments",
    "section": "Uploading a Jupyter Notebook to Google Colab",
    "text": "Uploading a Jupyter Notebook to Google Colab\nIf you have a jupyter notebook (.ipynb file), you can use it in Google Colab. First, you must upload the file to Google Drive. Afterwards, you can double click on the file and it should automatically open up in Google Colab. If it does not work, you can right-click on the file, select “Open With”, and then select “Google Colaboratory”:\n\nOnce in Google Colab, set the “Runtime” by following the instructions here.\nAfterwards, save the notebook from the “File” Menu, and “Move” the notebook to the location that you want it stored in your Google Drive. Note, your saved notebook may be in a new folder called “Google Colab” in Google Drive."
  },
  {
    "objectID": "posts/gc.html#google-assignments",
    "href": "posts/gc.html#google-assignments",
    "title": "Google Colab and Assignments",
    "section": "Google Assignments",
    "text": "Google Assignments\nIf you are using Canvas at your institution and you are allowed to use Google Assignments on Canvas, you can create what is known as Google Assignment to assign a Jupyter notebook to your students. This allows your students to access and submit a notebook from the confort of their course Canvas page.\n\nCreating an Assignment\nTo create a Google assignment, first go to the Assignments tab on your Course Canvas page. You will want to click on “+ Assignment” button to create a new assignmnent.\n\nScroll down to the “Submission Type” section and change “Online” to “External Tool” from the scroll down menu:\n\n\nA pop-up window will appear and scroll down and select the “Google Assignments (LTI X.X)”:\n\nA new window will pop-up that will configure the Google Assignment. Click the “Link” button indicating that you want to use a specific Google Account.\n\nClick the “Link” button again allowing Google Assignments to access your Google Drive.\n\nClick the “Attach” button to begin setting up\n\nNavigate through your Google Drive where the Google Colab notebook you wish to select is located.\n\nSelect a notebook and click the “Add Button”\n\nClick the “Create” button to create the assignment.\n\nBack to assignment page on Canvas, you will see which students have started the assignment and which students submitted the assignment."
  },
  {
    "objectID": "posts/gc.html#problems-with-google-colab",
    "href": "posts/gc.html#problems-with-google-colab",
    "title": "Google Colab and Assignments",
    "section": "Problems with Google Colab",
    "text": "Problems with Google Colab\n\nGoogle Colab has implemented the use of Gemini AI into the notebooks. Instructors may find this problematic where they want students to learn how to code with out the help of AI.\nSome students may have trouble accessing google assignments from their browsers. The solution is to have students access the assignment on a chromium-based browser.\nA notebook may be executing a code for an abnormally longer time than expected. The common cause is that the notebook got disconnected from the Google servers.\n\nCheck to make sure the laptop has internet.\nDownload the notebook as an ipynb.\n\nGoogle Servers Not Connecting. There are rare times when the Google Colab Server are down. Some students will not be able to access the server to execute code. Based on my experience (Isaac QS), it only happened once a year, and it only happened for one hour."
  },
  {
    "objectID": "posts/gc.html#resources",
    "href": "posts/gc.html#resources",
    "title": "Google Colab and Assignments",
    "section": "Resources",
    "text": "Resources"
  }
]